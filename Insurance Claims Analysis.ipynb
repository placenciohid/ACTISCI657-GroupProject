{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance Claims Analysis - Group Project ACT SCI 657"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team members of this project are:\n",
    "\n",
    "- Patrick Hsun\n",
    "- Dario Placencio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "We will be working with an insurance company claims dataset to conduct risk analytics. The dataset contains information related to policyholders, incidents, claims, and other factors that can help in assessing risks associated with insurance policies. The primary objective of our analysis is to identify patterns and trends in the data that can provide insights into potential risks and fraud. By applying statistical methods and data analysis techniques, we aim to identify high-risk factors, assess the impact of incidents on claims, and develop models to predict the likelihood of fraudulent claims. Our analysis will help the insurance company to make data-driven decisions to mitigate and manage risks effectively, and improve their overall risk management strategy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Variables\n",
    "\n",
    "The following are the variables of our dataset from the insurance company:\n",
    "\n",
    "- months_as_customer: The number of months the customer has been with the insurance company.\n",
    "- age: The age of the customer.\n",
    "- policy_number: The unique identification number assigned to the insurance policy.\n",
    "- policy_bind_date: The date when the insurance policy was bound or initiated.\n",
    "- policy_state: The state where the insurance policy is applicable.\n",
    "- policy_csl: The coverage limit of the insurance policy in the form of a combined single limit.\n",
    "- policy_deductible: The deductible amount specified in the insurance policy.\n",
    "- policy_annual_premium: The annual premium (cost) of the insurance policy.\n",
    "- umbrella_limit: The maximum coverage limit provided by an umbrella policy.\n",
    "- insured_zip: The ZIP code of the insured's residence.\n",
    "- insured_sex: The gender of the insured.\n",
    "- insured_education_level: The educational level of the insured.\n",
    "- insured_occupation: The occupation of the insured.\n",
    "- insured_hobbies: The hobbies or recreational activities of the insured.\n",
    "- insured_relationship: The relationship of the insured with the policyholder.\n",
    "- capital-gains: The amount of capital gains made by the insured.\n",
    "- capital-loss: The amount of capital losses incurred by the insured.\n",
    "- incident_date: The date when an incident or accident occurred.\n",
    "- incident_type: The type of incident or accident.\n",
    "- collision_type: The type of collision in case of an accident.\n",
    "- incident_severity: The severity of the incident or accident.\n",
    "- authorities_contacted: The authorities or agencies contacted after the incident.\n",
    "- incident_state: The state where the incident occurred.\n",
    "- incident_city: The city where the incident occurred.\n",
    "- incident_location: The specific location where the incident occurred.\n",
    "- incident_hour_of_the_day: The hour of the day when the incident occurred.\n",
    "- number_of_vehicles_involved: The number of vehicles involved in the incident.\n",
    "- property_damage: Indicates whether property damage occurred in the incident.\n",
    "- bodily_injuries: The number of bodily injuries reported in the incident.\n",
    "- witnesses: The presence witnesses present during the incident.\n",
    "- police_report_available: Indicates whether a police report is available for the incident.\n",
    "- total_claim_amount: The total amount claimed for the incident.\n",
    "- injury_claim: The amount claimed for bodily injuries in the incident.\n",
    "- property_claim: The amount claimed for property damage in the incident.\n",
    "- vehicle_claim: The amount claimed for vehicle damage in the incident.\n",
    "- auto_make: The make or manufacturer of the insured vehicle.\n",
    "- auto_model: The model of the insured vehicle.\n",
    "- auto_year: The manufacturing year of the insured vehicle.\n",
    "- fraud_reported: Indicates whether fraud was reported for the claim.\n",
    "_c39: This column seems to be an unnamed or unassigned column, possibly an artifact of the dataset or data processing. Its purpose is unclear."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "\n",
    "The data is sourced from Kaggle, it can be accessed through the following link:\n",
    "\n",
    "https://www.kaggle.com/datasets/buntyshah/auto-insurance-claims-data?datasetId=45152&sortBy=voteCount"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the xls file\n",
    "df=pd.read_excel('insurance_claims.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "2                 134   29         687698       2000-09-06           OH   \n",
       "3                 256   41         227811       1990-05-25           IL   \n",
       "4                 228   44         367455       2014-06-06           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
       "0       466132  ...                     YES              71610         6510   \n",
       "1       468176  ...                       ?               5070          780   \n",
       "2       430632  ...                      NO              34650         7700   \n",
       "3       608117  ...                      NO              63400         6340   \n",
       "4       610706  ...                      NO               6500         1300   \n",
       "\n",
       "  property_claim vehicle_claim  auto_make  auto_model auto_year  \\\n",
       "0          13020         52080       Saab         92x      2004   \n",
       "1            780          3510   Mercedes        E400      2007   \n",
       "2           3850         23100      Dodge         RAM      2007   \n",
       "3           6340         50720  Chevrolet       Tahoe      2014   \n",
       "4            650          4550     Accura         RSX      2009   \n",
       "\n",
       "  fraud_reported _c39  \n",
       "0              Y  NaN  \n",
       "1              Y  NaN  \n",
       "2              N  NaN  \n",
       "3              Y  NaN  \n",
       "4              N  NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['months_as_customer', 'age', 'policy_number', 'policy_bind_date',\n",
       "       'policy_state', 'policy_csl', 'policy_deductable',\n",
       "       'policy_annual_premium', 'umbrella_limit', 'insured_zip', 'insured_sex',\n",
       "       'insured_education_level', 'insured_occupation', 'insured_hobbies',\n",
       "       'insured_relationship', 'capital-gains', 'capital-loss',\n",
       "       'incident_date', 'incident_type', 'collision_type', 'incident_severity',\n",
       "       'authorities_contacted', 'incident_state', 'incident_city',\n",
       "       'incident_location', 'incident_hour_of_the_day',\n",
       "       'number_of_vehicles_involved', 'property_damage', 'bodily_injuries',\n",
       "       'witnesses', 'police_report_available', 'total_claim_amount',\n",
       "       'injury_claim', 'property_claim', 'vehicle_claim', 'auto_make',\n",
       "       'auto_model', 'auto_year', 'fraud_reported', '_c39'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the columns\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>capital-gains</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>203.954000</td>\n",
       "      <td>38.948000</td>\n",
       "      <td>546238.648000</td>\n",
       "      <td>1136.000000</td>\n",
       "      <td>1256.406150</td>\n",
       "      <td>1.101000e+06</td>\n",
       "      <td>501214.488000</td>\n",
       "      <td>25126.100000</td>\n",
       "      <td>-26793.700000</td>\n",
       "      <td>11.644000</td>\n",
       "      <td>1.83900</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.487000</td>\n",
       "      <td>52761.94000</td>\n",
       "      <td>7433.420000</td>\n",
       "      <td>7399.570000</td>\n",
       "      <td>37928.950000</td>\n",
       "      <td>2005.103000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.113174</td>\n",
       "      <td>9.140287</td>\n",
       "      <td>257063.005276</td>\n",
       "      <td>611.864673</td>\n",
       "      <td>244.167395</td>\n",
       "      <td>2.297407e+06</td>\n",
       "      <td>71701.610941</td>\n",
       "      <td>27872.187708</td>\n",
       "      <td>28104.096686</td>\n",
       "      <td>6.951373</td>\n",
       "      <td>1.01888</td>\n",
       "      <td>0.820127</td>\n",
       "      <td>1.111335</td>\n",
       "      <td>26401.53319</td>\n",
       "      <td>4880.951853</td>\n",
       "      <td>4824.726179</td>\n",
       "      <td>18886.252893</td>\n",
       "      <td>6.015861</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>100804.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>433.330000</td>\n",
       "      <td>-1.000000e+06</td>\n",
       "      <td>430104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-111100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>115.750000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>335980.250000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1089.607500</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>448404.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-51500.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41812.50000</td>\n",
       "      <td>4295.000000</td>\n",
       "      <td>4445.000000</td>\n",
       "      <td>30292.500000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>199.500000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>533135.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1257.200000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>466445.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23250.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58055.00000</td>\n",
       "      <td>6775.000000</td>\n",
       "      <td>6750.000000</td>\n",
       "      <td>42100.000000</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>276.250000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>759099.750000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1415.695000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>603251.000000</td>\n",
       "      <td>51025.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>70592.50000</td>\n",
       "      <td>11305.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>50822.500000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>479.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>999435.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2047.590000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>620962.000000</td>\n",
       "      <td>100500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>114920.00000</td>\n",
       "      <td>21450.000000</td>\n",
       "      <td>23670.000000</td>\n",
       "      <td>79560.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       months_as_customer          age  policy_number  policy_deductable  \\\n",
       "count         1000.000000  1000.000000    1000.000000        1000.000000   \n",
       "mean           203.954000    38.948000  546238.648000        1136.000000   \n",
       "std            115.113174     9.140287  257063.005276         611.864673   \n",
       "min              0.000000    19.000000  100804.000000         500.000000   \n",
       "25%            115.750000    32.000000  335980.250000         500.000000   \n",
       "50%            199.500000    38.000000  533135.000000        1000.000000   \n",
       "75%            276.250000    44.000000  759099.750000        2000.000000   \n",
       "max            479.000000    64.000000  999435.000000        2000.000000   \n",
       "\n",
       "       policy_annual_premium  umbrella_limit    insured_zip  capital-gains  \\\n",
       "count            1000.000000    1.000000e+03    1000.000000    1000.000000   \n",
       "mean             1256.406150    1.101000e+06  501214.488000   25126.100000   \n",
       "std               244.167395    2.297407e+06   71701.610941   27872.187708   \n",
       "min               433.330000   -1.000000e+06  430104.000000       0.000000   \n",
       "25%              1089.607500    0.000000e+00  448404.500000       0.000000   \n",
       "50%              1257.200000    0.000000e+00  466445.500000       0.000000   \n",
       "75%              1415.695000    0.000000e+00  603251.000000   51025.000000   \n",
       "max              2047.590000    1.000000e+07  620962.000000  100500.000000   \n",
       "\n",
       "        capital-loss  incident_hour_of_the_day  number_of_vehicles_involved  \\\n",
       "count    1000.000000               1000.000000                   1000.00000   \n",
       "mean   -26793.700000                 11.644000                      1.83900   \n",
       "std     28104.096686                  6.951373                      1.01888   \n",
       "min   -111100.000000                  0.000000                      1.00000   \n",
       "25%    -51500.000000                  6.000000                      1.00000   \n",
       "50%    -23250.000000                 12.000000                      1.00000   \n",
       "75%         0.000000                 17.000000                      3.00000   \n",
       "max         0.000000                 23.000000                      4.00000   \n",
       "\n",
       "       bodily_injuries    witnesses  total_claim_amount  injury_claim  \\\n",
       "count      1000.000000  1000.000000          1000.00000   1000.000000   \n",
       "mean          0.992000     1.487000         52761.94000   7433.420000   \n",
       "std           0.820127     1.111335         26401.53319   4880.951853   \n",
       "min           0.000000     0.000000           100.00000      0.000000   \n",
       "25%           0.000000     1.000000         41812.50000   4295.000000   \n",
       "50%           1.000000     1.000000         58055.00000   6775.000000   \n",
       "75%           2.000000     2.000000         70592.50000  11305.000000   \n",
       "max           2.000000     3.000000        114920.00000  21450.000000   \n",
       "\n",
       "       property_claim  vehicle_claim    auto_year  _c39  \n",
       "count     1000.000000    1000.000000  1000.000000   0.0  \n",
       "mean      7399.570000   37928.950000  2005.103000   NaN  \n",
       "std       4824.726179   18886.252893     6.015861   NaN  \n",
       "min          0.000000      70.000000  1995.000000   NaN  \n",
       "25%       4445.000000   30292.500000  2000.000000   NaN  \n",
       "50%       6750.000000   42100.000000  2005.000000   NaN  \n",
       "75%      10885.000000   50822.500000  2010.000000   NaN  \n",
       "max      23670.000000   79560.000000  2015.000000   NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary the numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 40 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   months_as_customer           1000 non-null   int64         \n",
      " 1   age                          1000 non-null   int64         \n",
      " 2   policy_number                1000 non-null   int64         \n",
      " 3   policy_bind_date             1000 non-null   datetime64[ns]\n",
      " 4   policy_state                 1000 non-null   object        \n",
      " 5   policy_csl                   1000 non-null   object        \n",
      " 6   policy_deductable            1000 non-null   int64         \n",
      " 7   policy_annual_premium        1000 non-null   float64       \n",
      " 8   umbrella_limit               1000 non-null   int64         \n",
      " 9   insured_zip                  1000 non-null   int64         \n",
      " 10  insured_sex                  1000 non-null   object        \n",
      " 11  insured_education_level      1000 non-null   object        \n",
      " 12  insured_occupation           1000 non-null   object        \n",
      " 13  insured_hobbies              1000 non-null   object        \n",
      " 14  insured_relationship         1000 non-null   object        \n",
      " 15  capital-gains                1000 non-null   int64         \n",
      " 16  capital-loss                 1000 non-null   int64         \n",
      " 17  incident_date                1000 non-null   datetime64[ns]\n",
      " 18  incident_type                1000 non-null   object        \n",
      " 19  collision_type               1000 non-null   object        \n",
      " 20  incident_severity            1000 non-null   object        \n",
      " 21  authorities_contacted        1000 non-null   object        \n",
      " 22  incident_state               1000 non-null   object        \n",
      " 23  incident_city                1000 non-null   object        \n",
      " 24  incident_location            1000 non-null   object        \n",
      " 25  incident_hour_of_the_day     1000 non-null   int64         \n",
      " 26  number_of_vehicles_involved  1000 non-null   int64         \n",
      " 27  property_damage              1000 non-null   object        \n",
      " 28  bodily_injuries              1000 non-null   int64         \n",
      " 29  witnesses                    1000 non-null   int64         \n",
      " 30  police_report_available      1000 non-null   object        \n",
      " 31  total_claim_amount           1000 non-null   int64         \n",
      " 32  injury_claim                 1000 non-null   int64         \n",
      " 33  property_claim               1000 non-null   int64         \n",
      " 34  vehicle_claim                1000 non-null   int64         \n",
      " 35  auto_make                    1000 non-null   object        \n",
      " 36  auto_model                   1000 non-null   object        \n",
      " 37  auto_year                    1000 non-null   int64         \n",
      " 38  fraud_reported               1000 non-null   object        \n",
      " 39  _c39                         0 non-null      float64       \n",
      "dtypes: datetime64[ns](2), float64(2), int64(17), object(19)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Info the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_c39    1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filet the columns with null values\n",
    "df.isnull().sum()[df.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop _c39 column\n",
    "df.drop('_c39',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the '?' with nan\n",
    "df.replace('?',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 39)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total amount of rows\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy_bind_date', 'policy_state', 'policy_csl', 'insured_sex', 'insured_education_level', 'insured_occupation', 'insured_hobbies', 'insured_relationship', 'incident_date', 'incident_type', 'collision_type', 'incident_severity', 'authorities_contacted', 'incident_state', 'incident_city', 'incident_location', 'property_damage', 'police_report_available', 'auto_make', 'auto_model', 'fraud_reported']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of column names with data type non-numerical\n",
    "cat_cols=df.select_dtypes(exclude=np.number).columns.tolist()\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the policy number, insurance zip, insurance location to the cat_cols list\n",
    "cat_cols.extend(['policy_number','insured_zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a funciton to count the unique values in each column\n",
    "def unique_values(df):\n",
    "    for i in df.columns:\n",
    "        print(i,df[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_bind_date 951\n",
      "policy_state 3\n",
      "policy_csl 3\n",
      "insured_sex 2\n",
      "insured_education_level 7\n",
      "insured_occupation 14\n",
      "insured_hobbies 20\n",
      "insured_relationship 6\n",
      "incident_date 60\n",
      "incident_type 4\n",
      "collision_type 3\n",
      "incident_severity 4\n",
      "authorities_contacted 5\n",
      "incident_state 7\n",
      "incident_city 7\n",
      "incident_location 1000\n",
      "property_damage 2\n",
      "police_report_available 2\n",
      "auto_make 14\n",
      "auto_model 39\n",
      "fraud_reported 2\n",
      "policy_number 1000\n",
      "insured_zip 995\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the categorical columns\n",
    "unique_values(df[cat_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the set of categorical variables, we can see that some of them have over 900 different values, which is something to keep in mind as we go further into the prediciton models.\n",
    "\n",
    "The variables on this condition are:\n",
    "\n",
    "- policy_blind_date\n",
    "- incident_location\n",
    "- policy_number\n",
    "- insured_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAE+CAYAAAAj7AywAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWVklEQVR4nO3df5Bdd32f8edtCewAdrDjlavoR6UwKiDTYJetBkKGISjBIg2RS2sipqQq0VRhogTINKRyO1NMM5p6CqRhAm6rJiFyAhgV6loJKcZVIMRpiiwbx7Zka6SgYG8lJGGSGhsiRsqnf9yjci1W0srW2e/d3ec1s3PP/d5zzv3If+w8PvfHpqqQJElSOxe1HkCSJGmuM8gkSZIaM8gkSZIaM8gkSZIaM8gkSZIaM8gkSZIam996gGfjyiuvrGXLlrUeQ5Ik6Zzuvffer1XV2GSPzeggW7ZsGbt37249hiRJ0jkl+cqZHvMlS0mSpMYMMkmSpMYMMkmSpMYMMkmSpMYMMkmSpMYMMkmSpMYMMkmSpMYMMkmSpMYMMkmSpMYMMkmSpMYMMkmSpMZm9N+ylKTZ4NF/+3dbjyDNSUv/zYOtR/j/vEImSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUWG9BluTFSe4f+nkiybuSXJHkriT7u9vLh465McmBJPuSXNfXbJIkSaOktyCrqn1VdU1VXQO8AvgmcDuwGdhZVSuAnd19kqwE1gFXA2uAW5LM62s+SZKkUTFdL1muBv68qr4CrAW2devbgOu77bXAbVV1vKoOAgeAVdM0nyRJUjPTFWTrgI9321dV1WGA7nZBt74IeGzomIluTZIkaVbrPciSPBf4SeC/nmvXSdZqkvNtTLI7ye5jx45diBElSZKamo4rZG8A7quqI939I0kWAnS3R7v1CWDJ0HGLgUOnn6yqtlbVeFWNj42N9Ti2JEnS9JiOIHsL33m5EmAHsL7bXg/cMbS+LsnFSZYDK4Bd0zCfJElSU/P7PHmS5wE/Bvzs0PLNwPYkG4BHgRsAqmpPku3AXuAEsKmqTvY5nyRJ0ijoNciq6pvA95229jiDT11Otv8WYEufM0mSJI0av6lfkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpsV6DLMkLk3wyySNJHk7yqiRXJLkryf7u9vKh/W9MciDJviTX9TmbJEnSqOj7CtkHgc9U1UuAlwMPA5uBnVW1AtjZ3SfJSmAdcDWwBrglybye55MkSWqutyBLchnwGuA3Aarq21X1V8BaYFu32zbg+m57LXBbVR2vqoPAAWBVX/NJkiSNij6vkP0AcAz4SJIvJfmNJM8HrqqqwwDd7YJu/0XAY0PHT3RrkiRJs1qfQTYf+HvAf6yqa4Gn6F6ePINMslbftVOyMcnuJLuPHTt2YSaVJElqqM8gmwAmquqL3f1PMgi0I0kWAnS3R4f2XzJ0/GLg0OknraqtVTVeVeNjY2O9DS9JkjRdeguyqvoq8FiSF3dLq4G9wA5gfbe2Hrij294BrEtycZLlwApgV1/zSZIkjYr5PZ//F4CPJnku8GXgbQwicHuSDcCjwA0AVbUnyXYG0XYC2FRVJ3ueT5Ikqbleg6yq7gfGJ3lo9Rn23wJs6XMmSZKkUeM39UuSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDVmkEmSJDXWa5Al+YskDya5P8nubu2KJHcl2d/dXj60/41JDiTZl+S6PmeTJEkaFdNxhexHquqaqhrv7m8GdlbVCmBnd58kK4F1wNXAGuCWJPOmYT5JkqSmWrxkuRbY1m1vA64fWr+tqo5X1UHgALBq+seTJEmaXn0HWQGfTXJvko3d2lVVdRigu13QrS8CHhs6dqJbkyRJmtXm93z+V1fVoSQLgLuSPHKWfTPJWn3XToOw2wiwdOnSCzOlJElSQ71eIauqQ93tUeB2Bi9BHkmyEKC7PdrtPgEsGTp8MXBoknNurarxqhofGxvrc3xJkqRp0VuQJXl+kktPbQOvBx4CdgDru93WA3d02zuAdUkuTrIcWAHs6ms+SZKkUdHnS5ZXAbcnOfU8H6uqzyS5B9ieZAPwKHADQFXtSbId2AucADZV1cke55MkSRoJvQVZVX0ZePkk648Dq89wzBZgS18zSZIkjSK/qV+SJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKkxg0ySJKmxKQVZkp1TWZMkSdL5m3+2B5NcAjwPuDLJ5UC6hy4Dvr/n2SRJkuaEswYZ8LPAuxjE1718J8ieAD7c31iSJElzx1mDrKo+CHwwyS9U1a9P00ySJElzyrmukAFQVb+e5IeAZcPHVNWtPc0lSZI0Z0wpyJL8DvAi4H7gZLdcgEEmSZL0LE0pyIBxYGVV1fk+QZJ5wG7g/1TVTyS5AvgEg6ttfwG8uar+stv3RmADg+h7R1Xdeb7PJ0mSNNNM9XvIHgL+1jN8jncCDw/d3wzsrKoVwM7uPklWAuuAq4E1wC1dzEmSJM1qUw2yK4G9Se5MsuPUz7kOSrIY+AfAbwwtrwW2ddvbgOuH1m+rquNVdRA4AKya4nySJEkz1lRfsrzpGZ7/14BfBi4dWruqqg4DVNXhJAu69UXA/x7ab6JbkyRJmtWm+inLPzrfEyf5CeBoVd2b5LVTOWSyp57kvBuBjQBLly4937EkSZJGzlQ/ZfkNvhNHzwWeAzxVVZed5bBXAz+Z5MeBS4DLkvwucCTJwu7q2ELgaLf/BLBk6PjFwKHTT1pVW4GtAOPj4+f9IQNJkqRRM6X3kFXVpVV1WfdzCfCPgA+d45gbq2pxVS1j8Gb9P6yqtwI7gPXdbuuBO7rtHcC6JBcnWQ6sAHad979IkiRphpnqe8iepqr+e5LNz/A5bwa2J9kAPArc0J1zT5LtwF7gBLCpqk6e+TSSJEmzw1RfsnzT0N2LGHwv2ZRfLqyqzwOf77YfB1afYb8twJapnleSJGk2mOoVsjcObZ9g8IWuay/4NJIkSXPQVD9l+ba+B5EkSZqrpvSm/iSLk9ye5GiSI0k+1X3pqyRJkp6lqX5T/0cYfAry+xl8WevvdWuSJEl6lqYaZGNV9ZGqOtH9/DYw1uNckiRJc8ZUg+xrSd6aZF7381bg8T4HkyRJmiumGmQ/A7wZ+CpwGPjHgG/0lyRJugCm+rUXvwKsr6q/BEhyBfB+BqEmSZKkZ2GqV8h+8FSMAVTV14Fr+xlJkiRpbplqkF2U5PJTd7orZM/ozy5JkiTp6aYaVR8A/leSTzL4k0lvxj9xJEmSdEFM9Zv6b02yG3gdEOBNVbW318kkSZLmiCm/7NgFmBEmSZJ0gU31PWSSJEnqiUEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUmEEmSZLUWG9BluSSJLuS/FmSPUne261fkeSuJPu728uHjrkxyYEk+5Jc19dskiRJo6TPK2THgddV1cuBa4A1SV4JbAZ2VtUKYGd3nyQrgXXA1cAa4JYk83qcT5IkaST0FmQ18GR39zndTwFrgW3d+jbg+m57LXBbVR2vqoPAAWBVX/NJkiSNil7fQ5ZkXpL7gaPAXVX1ReCqqjoM0N0u6HZfBDw2dPhEtyZJkjSr9RpkVXWyqq4BFgOrkrzsLLtnslN8107JxiS7k+w+duzYBZpUkiSpnWn5lGVV/RXweQbvDTuSZCFAd3u0220CWDJ02GLg0CTn2lpV41U1PjY21ufYkiRJ06LPT1mOJXlht/09wI8CjwA7gPXdbuuBO7rtHcC6JBcnWQ6sAHb1NZ8kSdKomN/juRcC27pPSl4EbK+q30/yp8D2JBuAR4EbAKpqT5LtwF7gBLCpqk72OJ8kSdJI6C3IquoB4NpJ1h8HVp/hmC3Alr5mkiRJGkV+U78kSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJj81sPMJO84t23th5BmpPufd8/bT2CJPXKK2SSJEmNGWSSJEmNGWSSJEmNGWSSJEmNGWSSJEmNGWSSJEmNGWSSJEmNGWSSJEmNGWSSJEmNGWSSJEmNGWSSJEmN9RZkSZYk+VySh5PsSfLObv2KJHcl2d/dXj50zI1JDiTZl+S6vmaTJEkaJX1eITsB/IuqeinwSmBTkpXAZmBnVa0Adnb36R5bB1wNrAFuSTKvx/kkSZJGQm9BVlWHq+q+bvsbwMPAImAtsK3bbRtwfbe9Fritqo5X1UHgALCqr/kkSZJGxbS8hyzJMuBa4IvAVVV1GAbRBizodlsEPDZ02ES3JkmSNKv1HmRJXgB8CnhXVT1xtl0nWatJzrcxye4ku48dO3ahxpQkSWqm1yBL8hwGMfbRqvpv3fKRJAu7xxcCR7v1CWDJ0OGLgUOnn7OqtlbVeFWNj42N9Te8JEnSNOnzU5YBfhN4uKp+deihHcD6bns9cMfQ+rokFydZDqwAdvU1nyRJ0qiY3+O5Xw38NPBgkvu7tX8F3AxsT7IBeBS4AaCq9iTZDuxl8AnNTVV1ssf5JEmSRkJvQVZVdzP5+8IAVp/hmC3Alr5mkiRJGkV+U78kSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjvQVZkt9KcjTJQ0NrVyS5K8n+7vbyocduTHIgyb4k1/U1lyRJ0qjp8wrZbwNrTlvbDOysqhXAzu4+SVYC64Cru2NuSTKvx9kkSZJGRm9BVlVfAL5+2vJaYFu3vQ24fmj9tqo6XlUHgQPAqr5mkyRJGiXT/R6yq6rqMEB3u6BbXwQ8NrTfRLcmSZI0643Km/ozyVpNumOyMcnuJLuPHTvW81iSJEn9m+4gO5JkIUB3e7RbnwCWDO23GDg02QmqamtVjVfV+NjYWK/DSpIkTYfpDrIdwPpuez1wx9D6uiQXJ1kOrAB2TfNskiRJTczv68RJPg68FrgyyQTwHuBmYHuSDcCjwA0AVbUnyXZgL3AC2FRVJ/uaTZIkaZT0FmRV9ZYzPLT6DPtvAbb0NY8kSdKoGpU39UuSJM1ZBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjBpkkSVJjIxdkSdYk2ZfkQJLNreeRJEnq20gFWZJ5wIeBNwArgbckWdl2KkmSpH6NVJABq4ADVfXlqvo2cBuwtvFMkiRJvRq1IFsEPDZ0f6JbkyRJmrXmtx7gNJlkrZ62Q7IR2NjdfTLJvt6n0mxxJfC11kPo/OX961uPIJ2Nv1tmqvdMlh29+ttnemDUgmwCWDJ0fzFwaHiHqtoKbJ3OoTQ7JNldVeOt55A0u/i7RRfCqL1keQ+wIsnyJM8F1gE7Gs8kSZLUq5G6QlZVJ5L8PHAnMA/4rara03gsSZKkXo1UkAFU1R8Af9B6Ds1KvtQtqQ/+btGzlqo6916SJEnqzai9h0ySJGnOMcg0q2Xg7iRvGFp7c5LPtJxL0syWpJJ8YOj+LyW5qeFImuEMMs1qNXhN/u3Arya5JMnzgS3ApraTSZrhjgNvSnJl60E0OxhkmvWq6iHg94B/CbwHuLWq/rztVJJmuBMM3sz/i60H0ewwcp+ylHryXuA+4NuAX+Ao6UL4MPBAkn/fehDNfAaZ5oSqeirJJ4Anq+p463kkzXxV9USSW4F3AN9qPY9mNl+y1FzyN92PJF0ovwZsAJ7feA7NcAaZJEnPUFV9HdjOIMqkZ8wgkyTp2fkA4Kct9az4Tf2SJEmNeYVMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMkiSpMYNMUnNJ3pHk4SQfvcDnfW2S37+Q53yGc7wwyc89g+NuSvJLfcwkabQYZJJGwc8BP15V/+TUQpJp/Vu7fT1fknnACxn8GyVpUgaZpKaS/CfgB4AdSf5vkq1JPgvcmmRZkj9Ocl/380PdMU+78pXkQ0n+Wbe9JskjSe4G3nSO577ptOcbS/KpJPd0P68e2u93kvxhkv1J/nm3niTvS/JQkgeT/NTQfJ9L8jHgQeBm4EVJ7k/yvm6fd3fP8UCS9w7N9K+T7EvyP4EXX5j/ypJG3bT+H6gkna6q3p5kDfAjwM8DbwR+uKq+leR5wI9V1V8nWQF8HBg/07mSXAL8F+B1wAHgE1MY4RVDz/cx4D9U1d1JlgJ3Ai/t9vtB4JUM/oj0l5J8GngVcA3wcgZ/OueeJF/o9l8FvKyqDiZZ1m1f0835emBFt08YxOhrgKeAdcC1DH4/3wfcO4V/g6QZziCTNGp2VNW3uu3nAB9Kcg1wEvg75zj2JcDBqtoPkOR3gY3n8Xw/CqxMcuqxy5Jc2m3f0e33rSSfYxBTPwx8vKpOAkeS/BHw94EngF1VdfAMz/n67udL3f0XMAi0S4Hbq+qb3fw7zjG7pFnCIJM0ap4a2v5F4AiDK1AXAX/drZ/g6W+5uGRo+3z/QO/w810EvGoo0ADoAu308xaDq1tTOe/pAvy7qvrPpz3PuyZ5HklzgO8hkzTKvhc4XFV/A/w0MK9b/wqDK1kXJ/leYHW3/giwPMmLuvtvOc/n+yyDl00B6K7MnbI2ySVJvg94LXAP8AXgp5LMSzIGvAbYNcl5v8Hg6tcpdwI/k+QF3fMsSrKgO98/TPI93ZW5N57n/JJmKK+QSRpltwCfSnID8Dm6q05V9ViS7cADwH66l/6695ptBD6d5GvA3cDLzuP53gF8OMkDDH4/fgF4e/fYLuDTwFLgV6rqUJLbGbyP7M8YXNn65ar6apKXDJ+0qh5P8idJHgL+R1W9O8lLgT/trr49Cby1qu5L8gngfgbR+cfnMbukGSxVXh2XpLNJchPwZFW9v/UskmYnX7KUJElqzCtkkma9JG8D3nna8p9U1aYW80jS6QwySZKkxnzJUpIkqTGDTJIkqTGDTJIkqTGDTJIkqTGDTJIkqbH/B71xFLuP+C4JAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check the target variable by plotting fraud_reported\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(df['fraud_reported']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    753\n",
       "Y    247\n",
       "Name: fraud_reported, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the fraud_reported\n",
    "df['fraud_reported'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a considerable difference between the fraud and non-fraud claims, but is expected given the nature of these events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of total claim amount\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.distplot(df['total_claim_amount']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SC    73\n",
       "NY    58\n",
       "WV    39\n",
       "NC    34\n",
       "VA    25\n",
       "OH    10\n",
       "PA     8\n",
       "Name: incident_state, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count fraud by Incident State, for Y fraud_reported\n",
    "df[df['fraud_reported']=='Y']['incident_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorbar": {
          "title": {
           "text": "Fraud Reported"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "locationmode": "USA-states",
         "locations": [
          "SC",
          "NY",
          "WV",
          "NC",
          "VA",
          "OH",
          "PA"
         ],
         "type": "choropleth",
         "z": [
          73,
          58,
          39,
          34,
          25,
          10,
          8
         ]
        }
       ],
       "layout": {
        "geo": {
         "scope": "usa"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Fraud Reported by State"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using a USA map to plot the count of fraud_reported = Y by state, color by number of fraud_reported\n",
    "\n",
    "# Import the required libraries\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a dataframe with the count of fraud_reported = Y by state\n",
    "df_state=df[df['fraud_reported']=='Y']['incident_state'].value_counts().reset_index()\n",
    "df_state.columns=['state','count']\n",
    "\n",
    "# Create a USA map\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations=df_state['state'], # Spatial coordinates\n",
    "    z = df_state['count'].astype(float), # Data to be color-coded\n",
    "    locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "    colorscale = 'Blues',\n",
    "    colorbar_title = \"Fraud Reported\",\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = 'Fraud Reported by State',\n",
    "    geo_scope='usa', # limite map scope to USA\n",
    ")\n",
    "\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Breakdown of insuranced education claim group by fraud_reported\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(df['insured_education_level'],hue=df['fraud_reported']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bin the age column group by fraud_reported\n",
    "df['age_bin']=pd.cut(df['age'],bins=[0,20,40,60,80,100],labels=['0-20','20-40','40-60','60-80','80-100'])\n",
    "\n",
    "# Plot Breakdown of insuranced age claim group by fraud_reported\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(df['age_bin'],hue=df['fraud_reported']);  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAE+CAYAAAAj7AywAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAf8UlEQVR4nO3dfZjXdZ3v8edbQAYVTW4iFBXWpRSFEIG1FU2tVTdLdM371HXbsJPurh2jo3k2qXNxnUxby8z1orS0Y97sqpu2RphlrmYhJApCijccI11B2hQ0OQHv88fvy/gDh2GGmd98hpnn47q+13x/n+/d+/f9OOOL721kJpIkSSpnh9IFSJIk9XYGMkmSpMIMZJIkSYUZyCRJkgozkEmSJBVmIJMkSSqsb+kCOmLIkCE5cuTI0mVIkiRt1fz581/JzKEtTduuA9nIkSOZN29e6TIkSZK2KiL+75amecpSkiSpMAOZJElSYQYySZKkwrbra8gkSVLn+uMf/8jy5ct58803S5ey3WpqamLEiBH069evzcsYyCRJUrPly5czcOBARo4cSUSULme7k5msWrWK5cuXM2rUqDYv5ylLSZLU7M0332Tw4MGGsW0UEQwePLjdRxgNZJIkaROGsY7Zlv1nIJMkSSrMQCZJklp19dVXs//++3PmmWd26nofeOABPvzhD3fqOrfF73//e6699tp2LzdjxgyuvPLKTqnBQCZJklp17bXXcu+993LzzTc3t61bt65La2jU9tavX7/NgawzGcgkSdIWffKTn+S5557j+OOPZ7fddmPatGkcffTRnH322SxbtozDDjuMCRMmMGHCBH7+858Dbz/ydcEFF/Cd73wHgNmzZ7PffvsxZcoU7rzzzla3PWPGjE22t3LlSk466SQmTZrEpEmTePjhh5vnO+usszjqqKMYPXo03/zmN4HaHY/Tp0/nwAMPZOzYsdx2223N9R155JGcccYZjB07losvvphnn32W8ePHM336dACuuOIKJk2axLhx47jsssuaa5o5cybvec97+OAHP8hTTz3VOTuZBj72IiL2Am4C3gVsAGZl5tciYgbwCWBlNevnMvPeaplLgI8D64G/z8wfNao+SdqSF744tnQJ7bb35xeWLkE91HXXXcfs2bP56U9/yjXXXMM999zDQw89xIABA3jjjTe47777aGpqYunSpZx++umtvmP6zTff5BOf+AQ/+clP+NM//VNOPfXUrW5//vz5zds744wz+PSnP82UKVN44YUXOOaYY1iyZAkATzzxBL/4xS94/fXXOeiggzjuuON45JFHWLBgAY8//jivvPIKkyZN4vDDDwdg7ty5LFq0iFGjRrFs2TIWLVrEggULAJgzZw5Lly5l7ty5ZCbHH388Dz74IDvvvDO33norjz32GOvWrWPChAkcfPDBHd/JNPY5ZOuAizLzVxExEJgfEfdV067KzE1OukbEGOA04ABgD+DHEfHuzFzfwBolSVI7HH/88QwYMACoPUT2ggsuYMGCBfTp04enn3661WV//etfM2rUKEaPHg3Axz72MWbNmtXm7f34xz9m8eLFzdNee+01Vq9eDcDUqVMZMGAAAwYM4Mgjj2Tu3Lk89NBDnH766fTp04dhw4bx/ve/n0cffZRdd92VyZMnb/E5YXPmzGHOnDkcdNBBAKxZs4alS5eyevVqTjzxRHbaaafm2jpLwwJZZr4EvFSNr46IJcCerSwyFbg1M9cCz0fEM8Bk4JFG1ShJktpn5513bh6/6qqrGDZsGI8//jgbNmygqakJgL59+7Jhw4bm+eqfydXeR0LUb2/Dhg088sgjzQGt3ubrjQgys03r3Vxmcskll3Deeedt0v7Vr361YY8E6ZJryCJiJHAQ8Muq6YKIeCIiboiI3au2PYHf1C22nNYDnCRJKujVV19l+PDh7LDDDnz3u99l/fraSa199tmHxYsXs3btWl599VXuv/9+APbbbz+ef/55nn32WQBuueWWdm3v6KOP5pprrmn+vPEUI8D3v/993nzzTVatWsUDDzzQfHrytttuY/369axcuZIHH3yQyZMnv229AwcObD7SBnDMMcdwww03sGbNGgB++9vfsmLFCg4//HDuuusu/vCHP7B69WruueeedtXfmoYHsojYBbgDuDAzXwP+GdgXGE/tCNpXNs7awuJvi7YRMS0i5kXEvJUrV7awiCRJ6gqf+tSnuPHGGznkkEN4+umnm4867bXXXpxyyimMGzeOM888s/nUX1NTE7NmzeK4445jypQp7LPPPu3a3tVXX828efMYN24cY8aM4brrrmueNnnyZI477jgOOeQQ/vEf/5E99tiDE088kXHjxvHe976Xo446ii9/+cu8613vett6Bw8ezKGHHsqBBx7I9OnTOfrooznjjDN43/vex9ixY/noRz/K6tWrmTBhAqeeeirjx4/npJNO4rDDDuvA3ttUtHY4r8Mrj+gH/AD4UWb+UwvTRwI/yMwDqwv6ycz/XU37ETAjM7d4ynLixInZ2sWDkrQtvKhfvdmSJUvYf//9S5fRLjNmzGCXXXbhM5/5TOlSmrW0HyNifmZObGn+hh0hi9pJ1uuBJfVhLCKG1812IrCoGr8bOC0i+kfEKGA0MLdR9UmSJHUXjbzL8lDgLGBhRCyo2j4HnB4R46mdjlwGnAeQmU9GxO3AYmp3aJ7vHZaSJPV83/72t/na1762Sduhhx7KN77xjTYtP2PGjAZU1bUaeZflQ7R8Xdi9rSwzE5jZqJokSVL3c+6553LuueeWLqMon9QvSZJUmIFMkiSpMAOZJElSYQYySZLUI2UmU6ZM4Yc//GFz2+23386xxx5bsKqWNfIuS0mSpGYHT7+pU9c3/4qzW50eEVx33XWcfPLJHHnkkaxfv55LL72U2bNnd2odncFAJkmSeqwDDzyQj3zkI1x++eW8/vrrnH322ey7776ly3obA5kkSerRLrvsMiZMmMCOO+5Id33Dj4FMkiT1aDvvvDOnnnoqu+yyC/379y9dTou8qF+SJPV4O+ywAzvs0H1jT/etTJIkqZcwkEmSJBXmNWSSJKlLbO0xFY3U3V9A7hEySZKkwgxkkiRJhRnIJEmSCjOQSZIkFWYgkyRJKsxAJkmSVJiBTJIk9VgRwUUXXdT8+corr+yWj8DwOWSSJKlLvPDFsZ26vr0/v3Cr8/Tv358777yTSy65hCFDhnTq9juTR8gkSVKP1bdvX6ZNm8ZVV11VupRWeYRMapDO/pdgo7XlX5qStD06//zzGTduHJ/97GdLl7JFHiGTJEk92q677srZZ5/N1VdfXbqULTKQSZKkHu/CCy/k+uuv5/XXXy9dSosMZJIkqccbNGgQp5xyCtdff33pUlpkIJMkSb3CRRddxCuvvFK6jBZ5Ub8kSeoSJW4eWrNmTfP4sGHDeOONN7q8hrbwCJkkSVJhBjJJkqTCDGSSJEmFGcgkSdImMrN0Cdu1bdl/BjJJktSsqamJVatWGcq2UWayatUqmpqa2rWcd1lKkqRmI0aMYPny5axcubJ0KdutpqYmRowY0a5lDGSSJKlZv379GDVqVOkyeh1PWUqSJBVmIJMkSSrMQCZJklSYgUySJKkwA5kkSVJhBjJJkqTCDGSSJEmFGcgkSZIKa1ggi4i9IuKnEbEkIp6MiH+o2gdFxH0RsbT6uXvdMpdExDMR8VREHNOo2iRJkrqTRh4hWwdclJn7A4cA50fEGOBi4P7MHA3cX32mmnYacABwLHBtRPRpYH2SJEndQsMCWWa+lJm/qsZXA0uAPYGpwI3VbDcCJ1TjU4FbM3NtZj4PPANMblR9kiRJ3UWXXEMWESOBg4BfAsMy8yWohTbgndVsewK/qVtsedUmSZLUozU8kEXELsAdwIWZ+Vprs7bQli2sb1pEzIuIeb6JXpIk9QQNDWQR0Y9aGLs5M++sml+OiOHV9OHAiqp9ObBX3eIjgBc3X2dmzsrMiZk5cejQoY0rXpIkqYs08i7LAK4HlmTmP9VNuhs4pxo/B/h+XftpEdE/IkYBo4G5japPkiSpu+jbwHUfCpwFLIyIBVXb54AvAbdHxMeBF4CTATLzyYi4HVhM7Q7N8zNzfQPrkyRJ6hYaFsgy8yFavi4M4ANbWGYmMLNRNUmSJHVHPqlfkiSpMAOZJElSYQYySZKkwgxkkiRJhRnIJEmSCjOQSZIkFWYgkyRJKsxAJkmSVJiBTJIkqTADmSRJUmEGMkmSpMIMZJIkSYUZyCRJkgozkEmSJBVmIJMkSSrMQCZJklSYgUySJKkwA5kkSVJhBjJJkqTCDGSSJEmFGcgkSZIKM5BJkiQVZiCTJEkqzEAmSZJUmIFMkiSpMAOZJElSYQYySZKkwgxkkiRJhRnIJEmSCjOQSZIkFWYgkyRJKsxAJkmSVJiBTJIkqTADmSRJUmEGMkmSpMIMZJIkSYUZyCRJkgozkEmSJBVmIJMkSSrMQCZJklSYgUySJKkwA5kkSVJhDQtkEXFDRKyIiEV1bTMi4rcRsaAaPlQ37ZKIeCYinoqIYxpVlyRJUnfTt4Hr/g5wDXDTZu1XZeaV9Q0RMQY4DTgA2AP4cUS8OzPXN7C+bu+FL44tXUK77f35haVLkCRpu9OwI2SZ+SDwuzbOPhW4NTPXZubzwDPA5EbVJkmS1J2UuIbsgoh4ojqluXvVtifwm7p5lldtkiRJPV5XB7J/BvYFxgMvAV+p2qOFebOlFUTEtIiYFxHzVq5c2ZAiJUmSulKXBrLMfDkz12fmBuCbvHVacjmwV92sI4AXt7COWZk5MTMnDh06tLEFS5IkdYEuDWQRMbzu44nAxjsw7wZOi4j+ETEKGA3M7craJEmSSmnYXZYRcQtwBDAkIpYDlwFHRMR4aqcjlwHnAWTmkxFxO7AYWAec39vvsJQkSb1HwwJZZp7eQvP1rcw/E5jZqHokSZK6qzadsoyI+9vSJkmSpPZr9QhZRDQBO1E77bg7b90NuSu1B7hKkiSpg7Z2yvI84EJq4Ws+bwWy14BvNK4sSZKk3qPVQJaZXwO+FhF/l5lf76KaJEmSepU2XdSfmV+PiD8HRtYvk5mbv6dSkiRJ7dSmQBYR36X2hP0FwMbHUSRvf3G4JEmS2qmtj72YCIzJzBZfZyRJkqRt19Yn9S8C3tXIQiRJknqrth4hGwIsjoi5wNqNjZl5fEOqkiRJ6kXaGshmNLIISZKk3qytd1n+rNGFSJIk9VZtvctyNbW7KgF2BPoBr2fmro0qTJIkqbdo6xGygfWfI+IEYHIjCpIkSept2nqX5SYy89+Aozq3FEmSpN6pracs/6ru4w7UnkvmM8kkSZI6QVvvsvxI3fg6YBkwtdOrkSRJ6oXaeg3ZuY0uRJIkqbdq0zVkETEiIu6KiBUR8XJE3BERIxpdnCRJUm/Q1ov6vw3cDewB7AncU7VJkiSpg9oayIZm5rczc101fAcY2sC6JEmSeo22BrJXIuJjEdGnGj4GrGpkYZIkSb1FWwPZ3wCnAP8JvAR8FPBCf0mSpE7Q1sde/C/gnMz8L4CIGARcSS2oSZIkqQPaeoRs3MYwBpCZvwMOakxJkiRJvUtbA9kOEbH7xg/VEbK2Hl2TJElSK9oaqr4C/Dwi/pXaK5NOAWY2rCpJkqRepK1P6r8pIuZRe6F4AH+VmYsbWpkkSVIv0ebTjlUAM4RJkiR1srZeQyZJkqQGMZBJkiQVZiCTJEkqzEAmSZJUmIFMkiSpMAOZJElSYQYySZKkwgxkkiRJhRnIJEmSCjOQSZIkFWYgkyRJKsxAJkmSVJiBTJIkqTADmSRJUmENC2QRcUNErIiIRXVtgyLivohYWv3cvW7aJRHxTEQ8FRHHNKouSZKk7qaRR8i+Axy7WdvFwP2ZORq4v/pMRIwBTgMOqJa5NiL6NLA2SZKkbqNhgSwzHwR+t1nzVODGavxG4IS69lszc21mPg88A0xuVG2SJEndSVdfQzYsM18CqH6+s2rfE/hN3XzLqzZJkqQer7tc1B8ttGWLM0ZMi4h5ETFv5cqVDS5LkiSp8bo6kL0cEcMBqp8rqvblwF51840AXmxpBZk5KzMnZubEoUOHNrRYSZKkrtDVgexu4Jxq/Bzg+3Xtp0VE/4gYBYwG5nZxbZIkSUX0bdSKI+IW4AhgSEQsBy4DvgTcHhEfB14ATgbIzCcj4nZgMbAOOD8z1zeqNkmSpO6kYYEsM0/fwqQPbGH+mcDMRtUjSZLUXXWXi/olSZJ6LQOZJElSYQYySZKkwgxkkiRJhRnIJEmSCjOQSZIkFWYgkyRJKsxAJkmSVJiBTJIkqTADmSRJUmEGMkmSpMIMZJIkSYUZyCRJkgozkEmSJBVmIJMkSSrMQCZJklSYgUySJKkwA5kkSVJhBjJJkqTCDGSSJEmF9S1dgNQWB0+/qXQJ7XbXwNIVSJK2Fx4hkyRJKswjZJIabns7wunRTUldzSNkkiRJhRnIJEmSCjOQSZIkFWYgkyRJKsxAJkmSVJiBTJIkqTADmSRJUmE+h0yS1KO88MWxpUtot70/v7B0CSrMI2SSJEmFGcgkSZIKM5BJkiQVZiCTJEkqzEAmSZJUmIFMkiSpMAOZJElSYQYySZKkwgxkkiRJhRnIJEmSCjOQSZIkFVbkXZYRsQxYDawH1mXmxIgYBNwGjASWAadk5n+VqE+SJJWxvb2LtLPeQ1ryCNmRmTk+MydWny8G7s/M0cD91WdJkqQerzudspwK3FiN3wicUK4USZKkrlMqkCUwJyLmR8S0qm1YZr4EUP18Z6HaJEmSulSRa8iAQzPzxYh4J3BfRPy6rQtWAW4awN57792o+iRJkrpMkUCWmS9WP1dExF3AZODliBiemS9FxHBgxRaWnQXMApg4cWK2dZsHT7+p44V3sbsGlq5AkiR1hS4/ZRkRO0fEwI3jwNHAIuBu4JxqtnOA73d1bZIkSSWUOEI2DLgrIjZu/3uZOTsiHgVuj4iPAy8AJxeoTZIkqct1eSDLzOeA97bQvgr4QFfXI0mSVFp3euyFJElSr2QgkyRJKsxAJkmSVJiBTJIkqTADmSRJUmEGMkmSpMIMZJIkSYUZyCRJkgozkEmSJBVmIJMkSSrMQCZJklSYgUySJKkwA5kkSVJhBjJJkqTCDGSSJEmFGcgkSZIKM5BJkiQV1rd0AZKk7uvg6TeVLqHd7hpYugKp/TxCJkmSVJiBTJIkqTADmSRJUmEGMkmSpMIMZJIkSYV5l6UkST2Ud8luPzxCJkmSVJiBTJIkqTADmSRJUmEGMkmSpMIMZJIkSYUZyCRJkgozkEmSJBVmIJMkSSrMQCZJklSYgUySJKkwA5kkSVJhBjJJkqTCDGSSJEmFGcgkSZIKM5BJkiQVZiCTJEkqzEAmSZJUmIFMkiSpsG4XyCLi2Ih4KiKeiYiLS9cjSZLUaN0qkEVEH+AbwF8CY4DTI2JM2aokSZIaq1sFMmAy8ExmPpeZ/w+4FZhauCZJkqSG6m6BbE/gN3Wfl1dtkiRJPVZkZukamkXEycAxmfm31eezgMmZ+Xd180wDplUf3wM81eWFdp0hwCuli9A2s/+2X/bd9s3+27715P7bJzOHtjShb1dXshXLgb3qPo8AXqyfITNnAbO6sqhSImJeZk4sXYe2jf23/bLvtm/23/att/Zfdztl+SgwOiJGRcSOwGnA3YVrkiRJaqhudYQsM9dFxAXAj4A+wA2Z+WThsiRJkhqqWwUygMy8F7i3dB3dRK84NduD2X/bL/tu+2b/bd96Zf91q4v6JUmSeqPudg2ZJElSr2Mg6yJteSVURNwQESsiYtFm7YMi4r6IWFr93L1u2iXVOp+KiGMa/T16spb2f0f3fUT8RUTMj4iF1c+j6qYdXLU/ExFXR0RU7f0j4raq/ZcRMbKBX7tHiIi9IuKnEbEkIp6MiH+o2jvaf5MjYkE1PB4RJ9ZNs/86SUQ0RcTcah8/GRFfqNo75W9fROwdEWsi4jN1bfZfJ4qIPhHxWET8oPrc0d+9kRHxh7rfv+vqpvXMvstMhwYP1G5QeBb4E2BH4HFgTAvzHQ5MABZt1v5l4OJq/GLg8mp8TLWu/sCoaht9Sn/f7XVoaf93dN8DBwF7VOMHAr+tmzYXeB8QwA+Bv6zaPwVcV42fBtxWet909wEYDkyoxgcCT1d91NH+2wnoW7eNFXWf7b/O678AdqnG+wG/BA7prL99wB3AvwCfqWuz/zq3D/878D3gB9Xnjv7ujWSz/xf29L7zCFnXaNMroTLzQeB3LSw/FbixGr8ROKGu/dbMXJuZzwPPVNvSNtjC/u/Qvs/MxzJz47P0ngSaqn/FDQd2zcxHsvbX46bN1r1xm/8KfGDjvwDVssx8KTN/VY2vBpZQe8tHR/vvjcxcV31sAmrpwf7rVFmzpvrYrxqSTvjbFxEnAM9R+/3b2Gb/daKIGAEcB3yrrrkh/9/qyX1nIOsaHX0l1LDMfAlq/+MB3tlJ69XWdea+Pwl4LDPXVvMu38LyzeuuwsCrwOAOfIdepTpNcRC1oywd7r+I+LOIeBJYCHyy6hP7r5NVp7wWUDsKeV9mdrj/ImJn4H8AX9hskv3Xub4KfBbYUNfWGX87R1WnQX8WEYfVLd8j+85A1jVaSuidcXtro9arrWvXvo+IA4DLgfPasLz9uo0iYhdqp6cuzMzXWpu1hbYW93Fm/jIzDwAmAZdERNNWlrf/tkFmrs/M8dTe0DI5Ig5sZfa27uMvAFfVHX1ry/L2XztExIeBFZk5v62LtNDW0v59Cdg7Mw+iOh0aEbtuZfntuu8MZF2jpVdCrai7WPGTW1n+5eow7cbDtStaWe+LqDO1a99HxIl1/TqxWm4EcBdwdmY+W7f8iM2X33zdEdEX2I2WT2WrTkT0oxbGbs7MO6vmDvffRpm5BHid2rWA9l+DZObvgQeAY+l4//0Z8OWIWAZcCHwuag8ft/86z6HA8dU+vhU4KiL+Dx3su+qU5iqAKuw9C7ybntx3pS9i6w0DtQfwPkftAsaNF/UfsIV5R/L2i/qvYNOLI79cjR/AphdHPocX9Xe0rzbZ/x3d98A7qvlOamHao9QuXN54YeqHqvbz2fTC1NtL75fuPlT78Cbgq5u1d7T/RvHWRfz7UPvDP8T+6/T+Gwq8oxofAPwH8OHO/NsHzGDTi/rtv87vxyN466L+jv7uDd3YTu2GuN8Cg3py3xUvoLcMwIeo3fn1LHDpFua5hdph2j9SS/ofr9oHA/cDS6ufg+qWubRa51NUd5o4bHMfvW3/d3TfA/+T2lGVBXXDO6tpE4FF1Tqu4a0HNTdRuyPsGWp3E/1J6X3T3QdgCrVTE0/U7ecPdUL/nUXtYvAFwK+AE+qm2X+d13/jgMeq/lsEfL5q77S/fbw9kNl/nd+PR/BWIOvo795J1e/e49Xv3kd6et/5pH5JkqTCvIZMkiSpMAOZJElSYQYySZKkwgxkkiRJhRnIJEmSCjOQSZIkFWYgk9SlIuIdEfGpus9HRMQPStbUGTb/XiVFxF9HxDVbmPbzrq5H0tYZyCR1tXcA3SK4dLJ30MXfq3o9TLtk5p83ohZJHWMgk7RFETEyIn4dEd+KiEURcXNEfDAiHo6IpRExOSIGRcS/RcQTEfGLiBhXLTsjIm6IiAci4rmI+PtqtV8C9q3eWXdF1bZLRPxrta2bIyKqdXwpIhZX676ylTo/EhG/jIjHIuLHETGsan9/3fvxHouIga2s47MRsTAiHo+IL1VtD9S9k3RI9b4+IuKAiJhbrfeJiBi9+feKmiuq/bYwIk6tlj0iIn4WEbdHxNPVdzyzWt/CiNi3mm9oRNwREY9Ww6F1+3VWRMyh9rqoLdkrImZHxFMRcVnd91xTV8cDLe13SQWUflWAg4ND9x2ovdtzHTCW2j/g5gM3UHuH3FTg34CvA5dV8x8FLKjGZwA/p/bOuiHAKqAfb39f6BHAq9ReErwD8Ai1VyENovZqlY1vFHlHK3XuXjff3wJfqcbvAQ6txnehei9lC8v/ZVXrTtXnje/MewCYWI0PAZZV418HzqzGd6T2/sXNv9dJwH1AH2AY8AIwvPq+v6/G+1N7R98XqmX+gep9nMD3gCnV+N7Akrr9Oh8Y0Mr++GtqrwEbXNW2qO57rGltv5f+b87BobcO7T7cLanXeT4zFwJExJPA/ZmZEbGQWgjZh1r4IDN/EhGDI2K3atl/z8y1wNqIWEEtmLRkbmYur7axoFrvL4A3gW9FxL8DrV1nNgK4LSKGUwtIz1ftDwP/FBE3A3du3EYLPgh8OzPfqL7H71rZFtTCy6URMaJa79IWDi5NAW7JzPXAyxHxM2AS8BrwaGa+VH3fZ4E51TILgSPrahpTt95d647w3Z2Zf9hKjfdl5qpqG3dW9czbbJ6W9vtDW1mvpAbwlKWkrVlbN76h7vMGoC+1o2Wb2/iS3Ppl11fzb20b66kdyVoHTAbuAE4AZrdS49eBazJzLHAetZcMk5lfonbEbADwi4jYbwvLR13N9dbx1t/Jpo2Nmfk94HjgD8CPIuKoLaxzS7a2T6m2+77MHF8Ne2bm6mra662su7nMrXzevI7W+kdSgxnIJHXUg8CZULsuCXglM19rZf7VwBav5dooInYBdsvMe4ELgfGtzL4btVN/AOfUrWPfzFyYmZdTOzq0pUA2B/ibiNipWm5Q1b4MOLga/2jdev8EeC4zrwbuBsa18L0eBE6NiD4RMRQ4HJjbyndoqaYL6rY5vh3LAvxFdX3fAGqB9uF2Li+pCxnIJHXUDGBiRDxB7cL2c1qbuTqN9nB1sfsVrcw6EPhBtd6fAZ/eSg3/EhH/AbxS135htZ3HqR3N+uEWappNLVjNq07dfaaadCXw36L2qIghdYucCiyq5t0PuKmF73UX8ATwOPAT4LOZ+Z+tfIfN/T3Vfo2IxcAn27Es1E49fhdYANyRmZufrpTUjWy8CFaSJEmFeIRMkiSpMC/glLTdiIhLgZM3a/6XzJzZxuXHUjuNV29tZv5ZZ9TX1SLiGODyzZqfz8wTS9Qjadt5ylKSJKkwT1lKkiQVZiCTJEkqzEAmSZJUmIFMkiSpMAOZJElSYf8fWrxQmP3O7H8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bin the months_as_customer column group by fraud_reported\n",
    "df['months_as_customer_bin']=pd.cut(df['months_as_customer'],bins=[0,100,200,300,400,500],labels=['0-100','100-200','200-300','300-400','400-500'])\n",
    "\n",
    "# Plot Breakdown of insuranced months_as_customer claim group by fraud_reported\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(df['months_as_customer_bin'],hue=df['fraud_reported']);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the for non-numerical variables we will have to generate dummy variables, let's drop the high volume distinct values variables. Let's also add incident date given the is a time series variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop=['policy_number','incident_location','policy_bind_date', 'insured_zip', 'incident_date', 'age_bin', 'months_as_customer_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluse the cols_to_drop from the cat_cols list\n",
    "cat_cols=[i for i in cat_cols if i not in cols_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns\n",
    "df.drop(cols_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy_state               object\n",
       "policy_csl                 object\n",
       "insured_sex                object\n",
       "insured_education_level    object\n",
       "insured_occupation         object\n",
       "insured_hobbies            object\n",
       "insured_relationship       object\n",
       "incident_type              object\n",
       "collision_type             object\n",
       "incident_severity          object\n",
       "authorities_contacted      object\n",
       "incident_state             object\n",
       "incident_city              object\n",
       "property_damage            object\n",
       "police_report_available    object\n",
       "auto_make                  object\n",
       "auto_model                 object\n",
       "fraud_reported             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the types of the cat_cols\n",
    "df[cat_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conver the cat_cols to object type\n",
    "df[cat_cols]=df[cat_cols].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the column of cat_cols as factors\n",
    "for i in cat_cols:\n",
    "    df[i]=df[i].astype('category')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the nan values with mode\n",
    "for i in cat_cols:\n",
    "    df[i].fillna(df[i].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 160)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the dummy variables for the cat_cols\n",
    "df=pd.get_dummies(df,columns=cat_cols,drop_first=False)\n",
    "\n",
    "# Check the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>capital-gains</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>...</th>\n",
       "      <th>auto_model_RSX</th>\n",
       "      <th>auto_model_Silverado</th>\n",
       "      <th>auto_model_TL</th>\n",
       "      <th>auto_model_Tahoe</th>\n",
       "      <th>auto_model_Ultima</th>\n",
       "      <th>auto_model_Wrangler</th>\n",
       "      <th>auto_model_X5</th>\n",
       "      <th>auto_model_X6</th>\n",
       "      <th>fraud_reported_N</th>\n",
       "      <th>fraud_reported_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>53300</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>35100</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>48900</td>\n",
       "      <td>-62400</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>66000</td>\n",
       "      <td>-46000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_deductable  policy_annual_premium  \\\n",
       "0                 328   48               1000                1406.91   \n",
       "1                 228   42               2000                1197.22   \n",
       "2                 134   29               2000                1413.14   \n",
       "3                 256   41               2000                1415.74   \n",
       "4                 228   44               1000                1583.91   \n",
       "\n",
       "   umbrella_limit  capital-gains  capital-loss  incident_hour_of_the_day  \\\n",
       "0               0          53300             0                         5   \n",
       "1         5000000              0             0                         8   \n",
       "2         5000000          35100             0                         7   \n",
       "3         6000000          48900        -62400                         5   \n",
       "4         6000000          66000        -46000                        20   \n",
       "\n",
       "   number_of_vehicles_involved  bodily_injuries  ...  auto_model_RSX  \\\n",
       "0                            1                1  ...               0   \n",
       "1                            1                0  ...               0   \n",
       "2                            3                2  ...               0   \n",
       "3                            1                1  ...               0   \n",
       "4                            1                0  ...               1   \n",
       "\n",
       "   auto_model_Silverado  auto_model_TL  auto_model_Tahoe  auto_model_Ultima  \\\n",
       "0                     0              0                 0                  0   \n",
       "1                     0              0                 0                  0   \n",
       "2                     0              0                 0                  0   \n",
       "3                     0              0                 1                  0   \n",
       "4                     0              0                 0                  0   \n",
       "\n",
       "   auto_model_Wrangler  auto_model_X5  auto_model_X6  fraud_reported_N  \\\n",
       "0                    0              0              0                 0   \n",
       "1                    0              0              0                 0   \n",
       "2                    0              0              0                 1   \n",
       "3                    0              0              0                 0   \n",
       "4                    0              0              0                 1   \n",
       "\n",
       "   fraud_reported_Y  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 0  \n",
       "3                 1  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM - Gamma Regression for Claim Amount Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the following section is to generate a prediction model for the claim amount. The model will be based on a Gamma Regression, which is a generalized linear model (GLM) for predicting continuous positive variables.\n",
    "\n",
    "As a business problem, insurance companies need to be able to predict the claim amount in order to set the premium for the policy. The premium is the amount of money that the policy holder pays to the insurance company in order to be covered. As other option, the interest to predict claim amount might be rooted on the need to predict the amount of money that the insurance company will have to pay to the policy holder, in a case of a claim, so the company can set aside the resources to react to the claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1000.00000\n",
       "mean      52761.94000\n",
       "std       26401.53319\n",
       "min         100.00000\n",
       "25%       41812.50000\n",
       "50%       58055.00000\n",
       "75%       70592.50000\n",
       "max      114920.00000\n",
       "Name: total_claim_amount, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe total_claim_amount\n",
    "df['total_claim_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sklearn required libraries\n",
    "from sklearn.linear_model import GammaRegressor\n",
    "from sklearn.preprocessing import StandardScaler     \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and split into train and test sets\n",
    "X = df.drop('total_claim_amount', axis=1)\n",
    "y = df['total_claim_amount']\n",
    "\n",
    "# Scale the predictor variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create a gamma regression model\n",
    "gamma_model = GammaRegressor()\n",
    "\n",
    "# Fit the model on the training data\n",
    "gamma_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gamma_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the performance metrics library\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.9032279261291358\n",
      "MAE: 6399.919834662378\n",
      "MSE: 65729364.59744215\n",
      "Adjusted R2: 0.7655729966792183\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Model Performance Metrics\n",
    "print('R2 Score:', r2_score(y_test, y_pred))\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Create a function to calculate the adjusted R2\n",
    "def adj_r2(X,y):\n",
    "    r2 = gamma_model.score(X,y)\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2\n",
    "\n",
    "# Calculate the adjusted R2\n",
    "print('Adjusted R2:', adj_r2(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results suggest that the gamma regression model is a good fit for the data. The high R2 score of 0.903 indicates that the model is able to explain approximately 90.3% of the variance in the claim amount, which is considered a high level of explanation.\n",
    "\n",
    "The MAE of 6399.92 is a relatively low value considering the range of claim amounts and indicates that the model's predictions are off by an average of $6,399.92.\n",
    "\n",
    "The adjusted R2 of 0.765 indicates that the model's performance may be slightly impacted by the number of predictor variables used, which is common in regression analysis.\n",
    "\n",
    "Overall, the results suggest that the gamma regression model is a good starting point for predicting claim amount and may provide relatively accurate predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gamma model had a considerable amount of variables, for efficiency purposes in a business setting, and better understanding of the most important variables, we will proceed to generate feature selection through backward elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables in the model: 159\n"
     ]
    }
   ],
   "source": [
    "# Count the variables in the model\n",
    "print('Number of variables in the model:', len(gamma_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=GammaRegressor(), n_features_to_select=10, verbose=1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a backward feature selection through recursive feature elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Create the RFE with a gamma regression estimator and 10 features to select\n",
    "rfe = RFE(estimator=GammaRegressor(), n_features_to_select=10, verbose=1)\n",
    "\n",
    "# Fit the eliminator to the data\n",
    "rfe.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'months_as_customer': 39, 'age': 86, 'policy_deductable': 92, 'policy_annual_premium': 84, 'umbrella_limit': 65, 'capital-gains': 126, 'capital-loss': 127, 'incident_hour_of_the_day': 8, 'number_of_vehicles_involved': 2, 'bodily_injuries': 103, 'witnesses': 37, 'injury_claim': 1, 'property_claim': 1, 'vehicle_claim': 1, 'auto_year': 24, 'policy_state_IL': 101, 'policy_state_IN': 144, 'policy_state_OH': 124, 'policy_csl_100/300': 25, 'policy_csl_250/500': 100, 'policy_csl_500/1000': 52, 'insured_sex_FEMALE': 97, 'insured_sex_MALE': 110, 'insured_education_level_Associate': 31, 'insured_education_level_College': 114, 'insured_education_level_High School': 99, 'insured_education_level_JD': 108, 'insured_education_level_MD': 120, 'insured_education_level_Masters': 132, 'insured_education_level_PhD': 23, 'insured_occupation_adm-clerical': 17, 'insured_occupation_armed-forces': 80, 'insured_occupation_craft-repair': 137, 'insured_occupation_exec-managerial': 69, 'insured_occupation_farming-fishing': 44, 'insured_occupation_handlers-cleaners': 20, 'insured_occupation_machine-op-inspct': 64, 'insured_occupation_other-service': 143, 'insured_occupation_priv-house-serv': 117, 'insured_occupation_prof-specialty': 47, 'insured_occupation_protective-serv': 142, 'insured_occupation_sales': 29, 'insured_occupation_tech-support': 28, 'insured_occupation_transport-moving': 42, 'insured_hobbies_base-jumping': 81, 'insured_hobbies_basketball': 36, 'insured_hobbies_board-games': 138, 'insured_hobbies_bungie-jumping': 113, 'insured_hobbies_camping': 18, 'insured_hobbies_chess': 63, 'insured_hobbies_cross-fit': 112, 'insured_hobbies_dancing': 131, 'insured_hobbies_exercise': 130, 'insured_hobbies_golf': 95, 'insured_hobbies_hiking': 135, 'insured_hobbies_kayaking': 145, 'insured_hobbies_movies': 33, 'insured_hobbies_paintball': 58, 'insured_hobbies_polo': 50, 'insured_hobbies_reading': 94, 'insured_hobbies_skydiving': 76, 'insured_hobbies_sleeping': 149, 'insured_hobbies_video-games': 70, 'insured_hobbies_yachting': 96, 'insured_relationship_husband': 78, 'insured_relationship_not-in-family': 77, 'insured_relationship_other-relative': 128, 'insured_relationship_own-child': 118, 'insured_relationship_unmarried': 90, 'insured_relationship_wife': 35, 'incident_type_Multi-vehicle Collision': 1, 'incident_type_Parked Car': 1, 'incident_type_Single Vehicle Collision': 1, 'incident_type_Vehicle Theft': 1, 'collision_type_Front Collision': 9, 'collision_type_Rear Collision': 1, 'collision_type_Side Collision': 10, 'incident_severity_Major Damage': 3, 'incident_severity_Minor Damage': 51, 'incident_severity_Total Loss': 4, 'incident_severity_Trivial Damage': 1, 'authorities_contacted_Ambulance': 7, 'authorities_contacted_Fire': 5, 'authorities_contacted_None': 1, 'authorities_contacted_Other': 6, 'authorities_contacted_Police': 12, 'incident_state_NC': 123, 'incident_state_NY': 15, 'incident_state_OH': 98, 'incident_state_PA': 104, 'incident_state_SC': 30, 'incident_state_VA': 56, 'incident_state_WV': 13, 'incident_city_Arlington': 141, 'incident_city_Columbus': 93, 'incident_city_Hillsdale': 87, 'incident_city_Northbend': 150, 'incident_city_Northbrook': 133, 'incident_city_Riverwood': 83, 'incident_city_Springfield': 121, 'property_damage_NO': 57, 'property_damage_YES': 75, 'police_report_available_NO': 27, 'police_report_available_YES': 48, 'auto_make_Accura': 91, 'auto_make_Audi': 55, 'auto_make_BMW': 62, 'auto_make_Chevrolet': 136, 'auto_make_Dodge': 40, 'auto_make_Ford': 147, 'auto_make_Honda': 105, 'auto_make_Jeep': 71, 'auto_make_Mercedes': 73, 'auto_make_Nissan': 38, 'auto_make_Saab': 140, 'auto_make_Suburu': 67, 'auto_make_Toyota': 49, 'auto_make_Volkswagen': 54, 'auto_model_3 Series': 122, 'auto_model_92x': 119, 'auto_model_93': 107, 'auto_model_95': 116, 'auto_model_A3': 72, 'auto_model_A5': 146, 'auto_model_Accord': 21, 'auto_model_C300': 60, 'auto_model_CRV': 61, 'auto_model_Camry': 22, 'auto_model_Civic': 115, 'auto_model_Corolla': 19, 'auto_model_E400': 14, 'auto_model_Escape': 34, 'auto_model_F150': 26, 'auto_model_Forrestor': 43, 'auto_model_Fusion': 125, 'auto_model_Grand Cherokee': 53, 'auto_model_Highlander': 59, 'auto_model_Impreza': 88, 'auto_model_Jetta': 139, 'auto_model_Legacy': 106, 'auto_model_M5': 41, 'auto_model_MDX': 111, 'auto_model_ML350': 74, 'auto_model_Malibu': 89, 'auto_model_Maxima': 82, 'auto_model_Neon': 79, 'auto_model_Passat': 32, 'auto_model_Pathfinder': 148, 'auto_model_RAM': 68, 'auto_model_RSX': 45, 'auto_model_Silverado': 109, 'auto_model_TL': 66, 'auto_model_Tahoe': 102, 'auto_model_Ultima': 46, 'auto_model_Wrangler': 134, 'auto_model_X5': 129, 'auto_model_X6': 85, 'fraud_reported_N': 11, 'fraud_reported_Y': 16}\n"
     ]
    }
   ],
   "source": [
    "# Print the features and their ranking (high = dropped early on)\n",
    "print(dict(zip(X.columns, rfe.ranking_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['injury_claim', 'property_claim', 'vehicle_claim',\n",
      "       'incident_type_Multi-vehicle Collision', 'incident_type_Parked Car',\n",
      "       'incident_type_Single Vehicle Collision', 'incident_type_Vehicle Theft',\n",
      "       'collision_type_Rear Collision', 'incident_severity_Trivial Damage',\n",
      "       'authorities_contacted_None'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the features that are not eliminated\n",
    "print(X.columns[rfe.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   feature  rank\n",
      "11                            injury_claim     1\n",
      "72  incident_type_Single Vehicle Collision     1\n",
      "73             incident_type_Vehicle Theft     1\n",
      "75           collision_type_Rear Collision     1\n",
      "80        incident_severity_Trivial Damage     1\n",
      "13                           vehicle_claim     1\n",
      "12                          property_claim     1\n",
      "71                incident_type_Parked Car     1\n",
      "70   incident_type_Multi-vehicle Collision     1\n",
      "83              authorities_contacted_None     1\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with the features\n",
    "df_features = pd.DataFrame({'feature':X.columns, 'rank':rfe.ranking_})\n",
    "\n",
    "# Print the top 10 features\n",
    "print(df_features.sort_values('rank').head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159,)\n"
     ]
    }
   ],
   "source": [
    "# rfe.support_ dimension\n",
    "print(rfe.support_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with the selected features\n",
    "\n",
    "# Load the data and split into train and test sets\n",
    "\n",
    "# Select the features from the RFE\n",
    "X = df[X.columns[rfe.support_]]\n",
    "y = df['total_claim_amount']\n",
    "\n",
    "# Scale the predictor variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create a gamma regression model\n",
    "gamma_model = GammaRegressor()\n",
    "\n",
    "# Fit the model on the training data\n",
    "gamma_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gamma_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.9299548625049532\n",
      "MAE: 5625.192386427644\n",
      "MSE: 47575940.00551911\n",
      "Adjusted R2: 0.8570003484138443\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Model Performance Metrics\n",
    "print('R2 Score:', r2_score(y_test, y_pred))\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Create a function to calculate the adjusted R2\n",
    "def adj_r2(X,y):\n",
    "    r2 = gamma_model.score(X,y)\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2\n",
    "\n",
    "# Calculate the adjusted R2\n",
    "print('Adjusted R2:', adj_r2(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison to the previous Gamma model, the feature selection reduced Gamma model has higher R2 score (0.930 vs 0.903) indicating that it is able to explain more of the variance in the claim amount.\n",
    "\n",
    "Moreover, the MAE of the feature selection reduced Gamma model is lower (5625.19 vs 6399.92) suggesting that the model's predictions are off by a smaller average amount, which is considered a good improvement.\n",
    "\n",
    "The MSE of the feature selection reduced Gamma model is also lower (47,575,940.01 vs 65,729,364.60) indicating that the model's predictions have a smaller spread of errors.\n",
    "\n",
    "Overall, the results suggest that the feature selection process has improved the performance of the Gamma model. The reduced set of predictors may have helped the model to better capture the underlying relationships between the predictor variables and the claim amount, leading to more accurate predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weibull Regression for Total Claim Amount Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Weibull hazard model is beneficial for the insurance company in multiple ways. It helps assess risks and set appropriate prices for policies. By predicting future claim amounts, it assists in estimating necessary reserves. The model supports the development of tailored insurance products based on claim analysis. It also aids in minimizing losses by implementing risk prevention strategies. Additionally, it helps identify and prevent fraudulent claims. In summary, the Weibull hazard model enhances risk management, pricing, reserves, product development, loss prevention, and fraud detection for insurers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into test and train sets, using random split\n",
    "train, test = train_test_split(df, test_size=0.5, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>lifelines.WeibullAFTFitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration col</th>\n",
       "      <td>'total_claim_amount'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of observations</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of events observed</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log-likelihood</th>\n",
       "      <td>-4871.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time fit was run</th>\n",
       "      <td>2023-05-10 21:42:38 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"min-width: 12px;\"></th>\n",
       "      <th style=\"min-width: 12px;\"></th>\n",
       "      <th style=\"min-width: 12px;\">coef</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef)</th>\n",
       "      <th style=\"min-width: 12px;\">se(coef)</th>\n",
       "      <th style=\"min-width: 12px;\">coef lower 95%</th>\n",
       "      <th style=\"min-width: 12px;\">coef upper 95%</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef) lower 95%</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef) upper 95%</th>\n",
       "      <th style=\"min-width: 12px;\">cmp to</th>\n",
       "      <th style=\"min-width: 12px;\">z</th>\n",
       "      <th style=\"min-width: 12px;\">p</th>\n",
       "      <th style=\"min-width: 12px;\">-log2(p)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"159\" valign=\"top\">lambda_</th>\n",
       "      <th>age</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_Ambulance</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_Fire</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_None</th>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_Other</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_Police</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Accura</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1649494.78</td>\n",
       "      <td>-3232950.46</td>\n",
       "      <td>3232950.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Audi</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_BMW</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1409495.60</td>\n",
       "      <td>-2762560.73</td>\n",
       "      <td>2762560.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Chevrolet</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>443785.12</td>\n",
       "      <td>-869802.98</td>\n",
       "      <td>869802.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Dodge</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Ford</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Honda</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1430931.90</td>\n",
       "      <td>-2804575.11</td>\n",
       "      <td>2804574.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Jeep</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1257234.62</td>\n",
       "      <td>-2464134.70</td>\n",
       "      <td>2464134.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Mercedes</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.92</td>\n",
       "      <td>665485.33</td>\n",
       "      <td>-1304327.37</td>\n",
       "      <td>1304327.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Nissan</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Saab</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Suburu</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Toyota</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_make_Volkswagen</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>437780.25</td>\n",
       "      <td>-858033.64</td>\n",
       "      <td>858033.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_3 Series</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1027265.65</td>\n",
       "      <td>-2013403.80</td>\n",
       "      <td>2013403.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_92x</th>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_93</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_95</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_A3</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_A5</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Accord</th>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1791530.18</td>\n",
       "      <td>-3511334.80</td>\n",
       "      <td>3511334.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_C300</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_CRV</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1829231.40</td>\n",
       "      <td>-3585227.78</td>\n",
       "      <td>3585227.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Camry</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Civic</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1931964.48</td>\n",
       "      <td>-3786580.91</td>\n",
       "      <td>3786580.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Corolla</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_E400</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Escape</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_F150</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Forrestor</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1028679.17</td>\n",
       "      <td>-2016174.22</td>\n",
       "      <td>2016174.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Fusion</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Grand Cherokee</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1241644.44</td>\n",
       "      <td>-2433578.49</td>\n",
       "      <td>2433578.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Highlander</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Impreza</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>941029.00</td>\n",
       "      <td>-1844383.02</td>\n",
       "      <td>1844382.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Jetta</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Legacy</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>982262.66</td>\n",
       "      <td>-1925199.58</td>\n",
       "      <td>1925199.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_M5</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>966787.97</td>\n",
       "      <td>-1894869.69</td>\n",
       "      <td>1894869.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_MDX</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1937997.56</td>\n",
       "      <td>-3798405.54</td>\n",
       "      <td>3798405.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_ML350</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Malibu</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>726381.65</td>\n",
       "      <td>-1423681.97</td>\n",
       "      <td>1423681.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Maxima</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Neon</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.91</td>\n",
       "      <td>393119.46</td>\n",
       "      <td>-770500.08</td>\n",
       "      <td>770499.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Passat</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Pathfinder</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_RAM</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>501908.99</td>\n",
       "      <td>-983723.65</td>\n",
       "      <td>983723.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_RSX</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1793934.00</td>\n",
       "      <td>-3516046.10</td>\n",
       "      <td>3516045.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Silverado</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.94</td>\n",
       "      <td>773607.93</td>\n",
       "      <td>-1516243.74</td>\n",
       "      <td>1516243.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_TL</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1735798.13</td>\n",
       "      <td>-3402101.91</td>\n",
       "      <td>3402101.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Tahoe</th>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.85</td>\n",
       "      <td>776380.90</td>\n",
       "      <td>-1521678.76</td>\n",
       "      <td>1521678.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Ultima</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_Wrangler</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1223047.72</td>\n",
       "      <td>-2397129.60</td>\n",
       "      <td>2397129.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_X5</th>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1134045.15</td>\n",
       "      <td>-2222687.80</td>\n",
       "      <td>2222687.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_model_X6</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1079039.75</td>\n",
       "      <td>-2114879.13</td>\n",
       "      <td>2114878.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_year</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodily_injuries</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gains</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type_Front Collision</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type_Rear Collision</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type_Side Collision</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud_reported</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_city_Arlington</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>213563.35</td>\n",
       "      <td>-418576.61</td>\n",
       "      <td>418576.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_city_Columbus</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>125718.07</td>\n",
       "      <td>-246403.01</td>\n",
       "      <td>246402.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_city_Hillsdale</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_city_Northbend</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>145676.60</td>\n",
       "      <td>-285521.01</td>\n",
       "      <td>285520.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_city_Northbrook</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>146460.28</td>\n",
       "      <td>-287057.02</td>\n",
       "      <td>287056.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_city_Riverwood</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>232548.06</td>\n",
       "      <td>-455785.92</td>\n",
       "      <td>455785.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_city_Springfield</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>226809.13</td>\n",
       "      <td>-444537.85</td>\n",
       "      <td>444537.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_severity_Major Damage</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>350151.47</td>\n",
       "      <td>-686284.40</td>\n",
       "      <td>686284.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_severity_Minor Damage</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>341364.04</td>\n",
       "      <td>-669061.37</td>\n",
       "      <td>669061.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_severity_Total Loss</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>351579.90</td>\n",
       "      <td>-689084.07</td>\n",
       "      <td>689083.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_severity_Trivial Damage</th>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.79</td>\n",
       "      <td>342871.36</td>\n",
       "      <td>-672015.75</td>\n",
       "      <td>672015.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_state_NC</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>23576.61</td>\n",
       "      <td>-46209.41</td>\n",
       "      <td>46209.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_state_NY</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>59253.91</td>\n",
       "      <td>-116135.67</td>\n",
       "      <td>116135.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_state_OH</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>43925.50</td>\n",
       "      <td>-86092.51</td>\n",
       "      <td>86092.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_state_PA</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_state_SC</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>54296.96</td>\n",
       "      <td>-106420.21</td>\n",
       "      <td>106419.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_state_VA</th>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.86</td>\n",
       "      <td>82658.34</td>\n",
       "      <td>-162007.52</td>\n",
       "      <td>162007.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_state_WV</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>52251.03</td>\n",
       "      <td>-102410.29</td>\n",
       "      <td>102410.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type_Multi-vehicle Collision</th>\n",
       "      <td>0.14</td>\n",
       "      <td>1.15</td>\n",
       "      <td>130565.20</td>\n",
       "      <td>-255902.94</td>\n",
       "      <td>255903.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type_Parked Car</th>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.34</td>\n",
       "      <td>142519.17</td>\n",
       "      <td>-279333.52</td>\n",
       "      <td>279331.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type_Single Vehicle Collision</th>\n",
       "      <td>0.14</td>\n",
       "      <td>1.15</td>\n",
       "      <td>133218.41</td>\n",
       "      <td>-261103.13</td>\n",
       "      <td>261103.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type_Vehicle Theft</th>\n",
       "      <td>-1.03</td>\n",
       "      <td>0.36</td>\n",
       "      <td>134120.23</td>\n",
       "      <td>-262871.86</td>\n",
       "      <td>262869.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>injury_claim</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.56</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>100.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_education_level_Associate</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>191615.44</td>\n",
       "      <td>-375559.48</td>\n",
       "      <td>375559.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_education_level_College</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>205078.68</td>\n",
       "      <td>-401946.96</td>\n",
       "      <td>401946.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_education_level_High School</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>202408.53</td>\n",
       "      <td>-396713.56</td>\n",
       "      <td>396713.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_education_level_JD</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>202730.11</td>\n",
       "      <td>-397343.83</td>\n",
       "      <td>397343.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_education_level_MD</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>213529.52</td>\n",
       "      <td>-418510.31</td>\n",
       "      <td>418510.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_education_level_Masters</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>215951.06</td>\n",
       "      <td>-423256.43</td>\n",
       "      <td>423256.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_education_level_PhD</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>216775.43</td>\n",
       "      <td>-424872.16</td>\n",
       "      <td>424871.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_base-jumping</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_basketball</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_board-games</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_bungie-jumping</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>139685.85</td>\n",
       "      <td>-273779.31</td>\n",
       "      <td>273779.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_camping</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>83639.66</td>\n",
       "      <td>-163930.78</td>\n",
       "      <td>163930.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_chess</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>72378.01</td>\n",
       "      <td>-141858.43</td>\n",
       "      <td>141858.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_cross-fit</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_dancing</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>150351.03</td>\n",
       "      <td>-294682.71</td>\n",
       "      <td>294682.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_exercise</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_golf</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_hiking</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>26882.55</td>\n",
       "      <td>-52688.97</td>\n",
       "      <td>52688.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_kayaking</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_movies</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>53323.76</td>\n",
       "      <td>-104512.79</td>\n",
       "      <td>104512.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_paintball</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>40903.25</td>\n",
       "      <td>-80168.98</td>\n",
       "      <td>80168.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_polo</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_reading</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>46179.73</td>\n",
       "      <td>-90510.73</td>\n",
       "      <td>90510.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_skydiving</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>113852.58</td>\n",
       "      <td>-223147.10</td>\n",
       "      <td>223146.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_sleeping</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_video-games</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>19008.84</td>\n",
       "      <td>-37256.74</td>\n",
       "      <td>37256.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_hobbies_yachting</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>18703.62</td>\n",
       "      <td>-36658.53</td>\n",
       "      <td>36658.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_adm-clerical</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_armed-forces</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_craft-repair</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_exec-managerial</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_farming-fishing</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_handlers-cleaners</th>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_machine-op-inspct</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_other-service</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_priv-house-serv</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_prof-specialty</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_protective-serv</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_sales</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_tech-support</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_occupation_transport-moving</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_relationship_husband</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>133409.12</td>\n",
       "      <td>-261477.19</td>\n",
       "      <td>261476.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_relationship_not-in-family</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>150639.57</td>\n",
       "      <td>-295248.25</td>\n",
       "      <td>295248.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_relationship_other-relative</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>151600.92</td>\n",
       "      <td>-297132.46</td>\n",
       "      <td>297132.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_relationship_own-child</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>142119.77</td>\n",
       "      <td>-278549.75</td>\n",
       "      <td>278549.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_relationship_unmarried</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>153107.33</td>\n",
       "      <td>-300085.00</td>\n",
       "      <td>300084.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_relationship_wife</th>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>133409.12</td>\n",
       "      <td>-261477.21</td>\n",
       "      <td>261476.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_sex_FEMALE</th>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>69021.38</td>\n",
       "      <td>-135279.65</td>\n",
       "      <td>135279.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_sex_MALE</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.81</td>\n",
       "      <td>67492.92</td>\n",
       "      <td>-132283.91</td>\n",
       "      <td>132283.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>months_as_customer</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police_report_available_NO</th>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.77</td>\n",
       "      <td>52606.47</td>\n",
       "      <td>-103107.04</td>\n",
       "      <td>103106.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police_report_available_YES</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.78</td>\n",
       "      <td>50873.44</td>\n",
       "      <td>-99710.36</td>\n",
       "      <td>99709.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_csl_100/300</th>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_csl_250/500</th>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_csl_500/1000</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_deductable</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_state_IL</th>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_state_IN</th>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_state_OH</th>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_claim</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.25</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>112.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_damage_NO</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_damage_YES</th>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>umbrella_limit</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vehicle_claim</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.29</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>582.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witnesses</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>10.85</td>\n",
       "      <td>51755.35</td>\n",
       "      <td>38130.35</td>\n",
       "      <td>-74723.25</td>\n",
       "      <td>74744.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho_</th>\n",
       "      <th>Intercept</th>\n",
       "      <td>2.51</td>\n",
       "      <td>12.32</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.59</td>\n",
       "      <td>11.41</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><br><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Concordance</th>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIC</th>\n",
       "      <td>10063.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log-likelihood ratio test</th>\n",
       "      <td>1951.30 on 158 df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-log2(p) of ll-ratio test</th>\n",
       "      <td>1015.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "\\begin{tabular}{llrrrrrrrrrrr}\n",
       " &  & coef & exp(coef) & se(coef) & coef lower 95% & coef upper 95% & exp(coef) lower 95% & exp(coef) upper 95% & cmp to & z & p & -log2(p) \\\\\n",
       "param & covariate &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
       "\\multirow[c]{159}{*}{lambda_} & age & 0.00 & 1.00 & 0.00 & -0.00 & 0.00 & 1.00 & 1.00 & 0.00 & 1.02 & 0.31 & 1.70 \\\\\n",
       " & authorities_contacted_Ambulance & -0.13 & 0.88 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & authorities_contacted_Fire & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & authorities_contacted_None & -0.23 & 0.80 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & authorities_contacted_Other & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & authorities_contacted_Police & -0.14 & 0.87 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_make_Accura & -0.11 & 0.90 & 1649494.78 & -3232950.46 & 3232950.25 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_make_Audi & -0.13 & 0.88 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_make_BMW & -0.12 & 0.89 & 1409495.60 & -2762560.73 & 2762560.50 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_make_Chevrolet & -0.12 & 0.89 & 443785.12 & -869802.98 & 869802.74 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_make_Dodge & -0.10 & 0.90 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_make_Ford & -0.12 & 0.88 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_make_Honda & -0.13 & 0.88 & 1430931.90 & -2804575.11 & 2804574.86 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_make_Jeep & -0.12 & 0.89 & 1257234.62 & -2464134.70 & 2464134.46 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_make_Mercedes & -0.09 & 0.92 & 665485.33 & -1304327.37 & 1304327.19 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_make_Nissan & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_make_Saab & -0.12 & 0.88 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_make_Suburu & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_make_Toyota & -0.11 & 0.90 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_make_Volkswagen & -0.12 & 0.89 & 437780.25 & -858033.64 & 858033.41 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_3 Series & -0.12 & 0.88 & 1027265.65 & -2013403.80 & 2013403.55 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_92x & -0.15 & 0.86 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_93 & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_95 & -0.09 & 0.92 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_A3 & -0.14 & 0.87 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_A5 & -0.11 & 0.90 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_Accord & -0.18 & 0.84 & 1791530.18 & -3511334.80 & 3511334.44 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_C300 & -0.14 & 0.87 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_CRV & -0.12 & 0.88 & 1829231.40 & -3585227.78 & 3585227.54 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_Camry & -0.11 & 0.90 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_Civic & -0.10 & 0.91 & 1931964.48 & -3786580.91 & 3786580.71 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_Corolla & -0.12 & 0.88 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_E400 & -0.01 & 0.99 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_Escape & -0.11 & 0.90 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_F150 & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_Forrestor & -0.10 & 0.90 & 1028679.17 & -2016174.22 & 2016174.02 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_Fusion & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_Grand Cherokee & -0.12 & 0.89 & 1241644.44 & -2433578.49 & 2433578.26 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_Highlander & -0.09 & 0.92 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_Impreza & -0.07 & 0.93 & 941029.00 & -1844383.02 & 1844382.87 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_Jetta & -0.11 & 0.90 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_Legacy & -0.14 & 0.87 & 982262.66 & -1925199.58 & 1925199.30 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_M5 & -0.08 & 0.92 & 966787.97 & -1894869.69 & 1894869.53 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_MDX & -0.12 & 0.88 & 1937997.56 & -3798405.54 & 3798405.29 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_ML350 & -0.13 & 0.88 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_Malibu & -0.10 & 0.90 & 726381.65 & -1423681.97 & 1423681.77 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_Maxima & -0.10 & 0.90 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_Neon & -0.09 & 0.91 & 393119.46 & -770500.08 & 770499.89 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_Passat & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_Pathfinder & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_RAM & -0.11 & 0.90 & 501908.99 & -983723.65 & 983723.44 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_RSX & -0.07 & 0.94 & 1793934.00 & -3516046.10 & 3516045.97 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_Silverado & -0.07 & 0.94 & 773607.93 & -1516243.74 & 1516243.61 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_TL & -0.09 & 0.91 & 1735798.13 & -3402101.91 & 3402101.73 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_Tahoe & -0.16 & 0.85 & 776380.90 & -1521678.76 & 1521678.43 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_Ultima & -0.11 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & auto_model_Wrangler & -0.12 & 0.89 & 1223047.72 & -2397129.60 & 2397129.36 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_X5 & -0.15 & 0.86 & 1134045.15 & -2222687.80 & 2222687.50 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_model_X6 & -0.09 & 0.92 & 1079039.75 & -2114879.13 & 2114878.96 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & auto_year & 0.00 & 1.00 & 0.00 & -0.00 & 0.00 & 1.00 & 1.00 & 0.00 & 0.94 & 0.35 & 1.52 \\\\\n",
       " & bodily_injuries & -0.01 & 0.99 & 0.01 & -0.02 & 0.00 & 0.98 & 1.00 & 0.00 & -1.37 & 0.17 & 2.55 \\\\\n",
       " & capital-gains & 0.00 & 1.00 & 0.00 & -0.00 & 0.00 & 1.00 & 1.00 & 0.00 & 0.59 & 0.55 & 0.85 \\\\\n",
       " & capital-loss & 0.00 & 1.00 & 0.00 & -0.00 & 0.00 & 1.00 & 1.00 & 0.00 & 0.87 & 0.38 & 1.38 \\\\\n",
       " & collision_type_Front Collision & -0.17 & 0.85 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & collision_type_Rear Collision & -0.17 & 0.84 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & collision_type_Side Collision & -0.17 & 0.84 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & fraud_reported & -0.01 & 0.99 & 0.01 & -0.04 & 0.02 & 0.96 & 1.02 & 0.00 & -0.69 & 0.49 & 1.03 \\\\\n",
       " & incident_city_Arlington & -0.13 & 0.88 & 213563.35 & -418576.61 & 418576.35 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_city_Columbus & -0.12 & 0.89 & 125718.07 & -246403.01 & 246402.77 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_city_Hillsdale & -0.13 & 0.88 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & incident_city_Northbend & -0.12 & 0.88 & 145676.60 & -285521.01 & 285520.76 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_city_Northbrook & -0.14 & 0.87 & 146460.28 & -287057.02 & 287056.74 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_city_Riverwood & -0.11 & 0.90 & 232548.06 & -455785.92 & 455785.70 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_city_Springfield & -0.12 & 0.88 & 226809.13 & -444537.85 & 444537.60 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_hour_of_the_day & 0.00 & 1.00 & 0.00 & -0.00 & 0.00 & 1.00 & 1.00 & 0.00 & 0.23 & 0.82 & 0.29 \\\\\n",
       " & incident_severity_Major Damage & -0.13 & 0.88 & 350151.47 & -686284.40 & 686284.13 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_severity_Minor Damage & -0.14 & 0.87 & 341364.04 & -669061.37 & 669061.08 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_severity_Total Loss & -0.14 & 0.87 & 351579.90 & -689084.07 & 689083.79 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_severity_Trivial Damage & -0.24 & 0.79 & 342871.36 & -672015.75 & 672015.28 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_state_NC & -0.11 & 0.90 & 23576.61 & -46209.41 & 46209.19 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_state_NY & -0.14 & 0.87 & 59253.91 & -116135.67 & 116135.40 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_state_OH & -0.11 & 0.89 & 43925.50 & -86092.51 & 86092.28 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_state_PA & -0.09 & 0.92 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & incident_state_SC & -0.14 & 0.87 & 54296.96 & -106420.21 & 106419.94 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_state_VA & -0.15 & 0.86 & 82658.34 & -162007.52 & 162007.23 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_state_WV & -0.14 & 0.87 & 52251.03 & -102410.29 & 102410.00 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_type_Multi-vehicle Collision & 0.14 & 1.15 & 130565.20 & -255902.94 & 255903.22 & 0.00 & inf & 0.00 & 0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_type_Parked Car & -1.07 & 0.34 & 142519.17 & -279333.52 & 279331.37 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_type_Single Vehicle Collision & 0.14 & 1.15 & 133218.41 & -261103.13 & 261103.42 & 0.00 & inf & 0.00 & 0.00 & 1.00 & 0.00 \\\\\n",
       " & incident_type_Vehicle Theft & -1.03 & 0.36 & 134120.23 & -262871.86 & 262869.80 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & injury_claim & 0.00 & 1.00 & 0.00 & 0.00 & 0.00 & 1.00 & 1.00 & 0.00 & 11.56 & 0.00 & 100.21 \\\\\n",
       " & insured_education_level_Associate & -0.12 & 0.89 & 191615.44 & -375559.48 & 375559.24 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_education_level_College & -0.13 & 0.88 & 205078.68 & -401946.96 & 401946.70 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_education_level_High School & -0.13 & 0.88 & 202408.53 & -396713.56 & 396713.31 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_education_level_JD & -0.12 & 0.89 & 202730.11 & -397343.83 & 397343.59 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_education_level_MD & -0.13 & 0.88 & 213529.52 & -418510.31 & 418510.05 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_education_level_Masters & -0.13 & 0.88 & 215951.06 & -423256.43 & 423256.17 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_education_level_PhD & -0.12 & 0.89 & 216775.43 & -424872.16 & 424871.92 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_hobbies_base-jumping & -0.11 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_hobbies_basketball & -0.13 & 0.88 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_hobbies_board-games & -0.14 & 0.87 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_hobbies_bungie-jumping & -0.08 & 0.92 & 139685.85 & -273779.31 & 273779.15 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_hobbies_camping & -0.07 & 0.93 & 83639.66 & -163930.78 & 163930.64 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_hobbies_chess & -0.14 & 0.87 & 72378.01 & -141858.43 & 141858.15 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_hobbies_cross-fit & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_hobbies_dancing & -0.11 & 0.90 & 150351.03 & -294682.71 & 294682.50 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_hobbies_exercise & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_hobbies_golf & -0.09 & 0.92 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_hobbies_hiking & -0.13 & 0.87 & 26882.55 & -52688.97 & 52688.70 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_hobbies_kayaking & -0.13 & 0.88 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_hobbies_movies & -0.13 & 0.88 & 53323.76 & -104512.79 & 104512.53 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_hobbies_paintball & -0.08 & 0.92 & 40903.25 & -80168.98 & 80168.82 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_hobbies_polo & -0.14 & 0.87 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_hobbies_reading & -0.12 & 0.89 & 46179.73 & -90510.73 & 90510.50 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_hobbies_skydiving & -0.14 & 0.87 & 113852.58 & -223147.10 & 223146.82 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_hobbies_sleeping & -0.11 & 0.90 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_hobbies_video-games & -0.10 & 0.90 & 19008.84 & -37256.74 & 37256.53 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_hobbies_yachting & -0.10 & 0.90 & 18703.62 & -36658.53 & 36658.33 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_occupation_adm-clerical & -0.13 & 0.88 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_armed-forces & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_craft-repair & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_exec-managerial & -0.10 & 0.90 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_farming-fishing & -0.07 & 0.93 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_handlers-cleaners & -0.15 & 0.86 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_machine-op-inspct & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_other-service & -0.11 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_priv-house-serv & -0.11 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_prof-specialty & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_protective-serv & -0.12 & 0.89 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_sales & -0.11 & 0.90 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_tech-support & -0.13 & 0.88 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_occupation_transport-moving & -0.10 & 0.90 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & insured_relationship_husband & -0.13 & 0.88 & 133409.12 & -261477.19 & 261476.94 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_relationship_not-in-family & -0.12 & 0.89 & 150639.57 & -295248.25 & 295248.02 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_relationship_other-relative & -0.13 & 0.88 & 151600.92 & -297132.46 & 297132.21 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_relationship_own-child & -0.13 & 0.88 & 142119.77 & -278549.75 & 278549.50 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_relationship_unmarried & -0.14 & 0.87 & 153107.33 & -300085.00 & 300084.72 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_relationship_wife & -0.14 & 0.87 & 133409.12 & -261477.21 & 261476.93 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_sex_FEMALE & -0.22 & 0.80 & 69021.38 & -135279.65 & 135279.21 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & insured_sex_MALE & -0.21 & 0.81 & 67492.92 & -132283.91 & 132283.49 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & months_as_customer & -0.00 & 1.00 & 0.00 & -0.00 & 0.00 & 1.00 & 1.00 & 0.00 & -1.06 & 0.29 & 1.79 \\\\\n",
       " & number_of_vehicles_involved & -0.00 & 1.00 & 0.02 & -0.03 & 0.03 & 0.97 & 1.03 & 0.00 & -0.05 & 0.96 & 0.05 \\\\\n",
       " & police_report_available_NO & -0.26 & 0.77 & 52606.47 & -103107.04 & 103106.52 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & police_report_available_YES & -0.25 & 0.78 & 50873.44 & -99710.36 & 99709.86 & 0.00 & inf & 0.00 & -0.00 & 1.00 & 0.00 \\\\\n",
       " & policy_annual_premium & -0.00 & 1.00 & 0.00 & -0.00 & 0.00 & 1.00 & 1.00 & 0.00 & -0.53 & 0.60 & 0.75 \\\\\n",
       " & policy_csl_100/300 & -0.16 & 0.85 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & policy_csl_250/500 & -0.16 & 0.86 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & policy_csl_500/1000 & -0.17 & 0.85 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & policy_deductable & 0.00 & 1.00 & 0.00 & -0.00 & 0.00 & 1.00 & 1.00 & 0.00 & 0.84 & 0.40 & 1.33 \\\\\n",
       " & policy_state_IL & -0.18 & 0.84 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & policy_state_IN & -0.15 & 0.86 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & policy_state_OH & -0.16 & 0.85 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & property_claim & 0.00 & 1.00 & 0.00 & 0.00 & 0.00 & 1.00 & 1.00 & 0.00 & 12.25 & 0.00 & 112.22 \\\\\n",
       " & property_damage_NO & -0.25 & 0.78 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & property_damage_YES & -0.24 & 0.78 & nan & nan & nan & nan & nan & 0.00 & nan & nan & nan \\\\\n",
       " & umbrella_limit & 0.00 & 1.00 & 0.00 & -0.00 & 0.00 & 1.00 & 1.00 & 0.00 & 0.48 & 0.63 & 0.67 \\\\\n",
       " & vehicle_claim & 0.00 & 1.00 & 0.00 & 0.00 & 0.00 & 1.00 & 1.00 & 0.00 & 28.29 & 0.00 & 582.42 \\\\\n",
       " & witnesses & -0.00 & 1.00 & 0.00 & -0.01 & 0.00 & 0.99 & 1.00 & 0.00 & -0.85 & 0.39 & 1.34 \\\\\n",
       " & Intercept & 10.85 & 51755.35 & 38130.35 & -74723.25 & 74744.96 & 0.00 & inf & 0.00 & 0.00 & 1.00 & 0.00 \\\\\n",
       "rho_ & Intercept & 2.51 & 12.32 & 0.04 & 2.43 & 2.59 & 11.41 & 13.30 & 0.00 & 64.00 & 0.00 & inf \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "<lifelines.WeibullAFTFitter: fitted with 500 total observations, 0 right-censored observations>\n",
       "             duration col = 'total_claim_amount'\n",
       "   number of observations = 500\n",
       "number of events observed = 500\n",
       "           log-likelihood = -4871.89\n",
       "         time fit was run = 2023-05-10 21:42:38 UTC\n",
       "\n",
       "---\n",
       "                                                 coef  exp(coef)   se(coef)   coef lower 95%   coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
       "param   covariate                                                                                                                                      \n",
       "lambda_ age                                      0.00       1.00       0.00            -0.00             0.00                 1.00                 1.00\n",
       "        authorities_contacted_Ambulance         -0.13       0.88        NaN              NaN              NaN                  NaN                  NaN\n",
       "        authorities_contacted_Fire              -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        authorities_contacted_None              -0.23       0.80        NaN              NaN              NaN                  NaN                  NaN\n",
       "        authorities_contacted_Other             -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        authorities_contacted_Police            -0.14       0.87        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_make_Accura                        -0.11       0.90 1649494.78      -3232950.46       3232950.25                 0.00                  inf\n",
       "        auto_make_Audi                          -0.13       0.88        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_make_BMW                           -0.12       0.89 1409495.60      -2762560.73       2762560.50                 0.00                  inf\n",
       "        auto_make_Chevrolet                     -0.12       0.89  443785.12       -869802.98        869802.74                 0.00                  inf\n",
       "        auto_make_Dodge                         -0.10       0.90        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_make_Ford                          -0.12       0.88        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_make_Honda                         -0.13       0.88 1430931.90      -2804575.11       2804574.86                 0.00                  inf\n",
       "        auto_make_Jeep                          -0.12       0.89 1257234.62      -2464134.70       2464134.46                 0.00                  inf\n",
       "        auto_make_Mercedes                      -0.09       0.92  665485.33      -1304327.37       1304327.19                 0.00                  inf\n",
       "        auto_make_Nissan                        -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_make_Saab                          -0.12       0.88        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_make_Suburu                        -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_make_Toyota                        -0.11       0.90        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_make_Volkswagen                    -0.12       0.89  437780.25       -858033.64        858033.41                 0.00                  inf\n",
       "        auto_model_3 Series                     -0.12       0.88 1027265.65      -2013403.80       2013403.55                 0.00                  inf\n",
       "        auto_model_92x                          -0.15       0.86        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_93                           -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_95                           -0.09       0.92        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_A3                           -0.14       0.87        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_A5                           -0.11       0.90        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_Accord                       -0.18       0.84 1791530.18      -3511334.80       3511334.44                 0.00                  inf\n",
       "        auto_model_C300                         -0.14       0.87        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_CRV                          -0.12       0.88 1829231.40      -3585227.78       3585227.54                 0.00                  inf\n",
       "        auto_model_Camry                        -0.11       0.90        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_Civic                        -0.10       0.91 1931964.48      -3786580.91       3786580.71                 0.00                  inf\n",
       "        auto_model_Corolla                      -0.12       0.88        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_E400                         -0.01       0.99        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_Escape                       -0.11       0.90        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_F150                         -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_Forrestor                    -0.10       0.90 1028679.17      -2016174.22       2016174.02                 0.00                  inf\n",
       "        auto_model_Fusion                       -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_Grand Cherokee               -0.12       0.89 1241644.44      -2433578.49       2433578.26                 0.00                  inf\n",
       "        auto_model_Highlander                   -0.09       0.92        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_Impreza                      -0.07       0.93  941029.00      -1844383.02       1844382.87                 0.00                  inf\n",
       "        auto_model_Jetta                        -0.11       0.90        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_Legacy                       -0.14       0.87  982262.66      -1925199.58       1925199.30                 0.00                  inf\n",
       "        auto_model_M5                           -0.08       0.92  966787.97      -1894869.69       1894869.53                 0.00                  inf\n",
       "        auto_model_MDX                          -0.12       0.88 1937997.56      -3798405.54       3798405.29                 0.00                  inf\n",
       "        auto_model_ML350                        -0.13       0.88        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_Malibu                       -0.10       0.90  726381.65      -1423681.97       1423681.77                 0.00                  inf\n",
       "        auto_model_Maxima                       -0.10       0.90        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_Neon                         -0.09       0.91  393119.46       -770500.08        770499.89                 0.00                  inf\n",
       "        auto_model_Passat                       -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_Pathfinder                   -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_RAM                          -0.11       0.90  501908.99       -983723.65        983723.44                 0.00                  inf\n",
       "        auto_model_RSX                          -0.07       0.94 1793934.00      -3516046.10       3516045.97                 0.00                  inf\n",
       "        auto_model_Silverado                    -0.07       0.94  773607.93      -1516243.74       1516243.61                 0.00                  inf\n",
       "        auto_model_TL                           -0.09       0.91 1735798.13      -3402101.91       3402101.73                 0.00                  inf\n",
       "        auto_model_Tahoe                        -0.16       0.85  776380.90      -1521678.76       1521678.43                 0.00                  inf\n",
       "        auto_model_Ultima                       -0.11       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        auto_model_Wrangler                     -0.12       0.89 1223047.72      -2397129.60       2397129.36                 0.00                  inf\n",
       "        auto_model_X5                           -0.15       0.86 1134045.15      -2222687.80       2222687.50                 0.00                  inf\n",
       "        auto_model_X6                           -0.09       0.92 1079039.75      -2114879.13       2114878.96                 0.00                  inf\n",
       "        auto_year                                0.00       1.00       0.00            -0.00             0.00                 1.00                 1.00\n",
       "        bodily_injuries                         -0.01       0.99       0.01            -0.02             0.00                 0.98                 1.00\n",
       "        capital-gains                            0.00       1.00       0.00            -0.00             0.00                 1.00                 1.00\n",
       "        capital-loss                             0.00       1.00       0.00            -0.00             0.00                 1.00                 1.00\n",
       "        collision_type_Front Collision          -0.17       0.85        NaN              NaN              NaN                  NaN                  NaN\n",
       "        collision_type_Rear Collision           -0.17       0.84        NaN              NaN              NaN                  NaN                  NaN\n",
       "        collision_type_Side Collision           -0.17       0.84        NaN              NaN              NaN                  NaN                  NaN\n",
       "        fraud_reported                          -0.01       0.99       0.01            -0.04             0.02                 0.96                 1.02\n",
       "        incident_city_Arlington                 -0.13       0.88  213563.35       -418576.61        418576.35                 0.00                  inf\n",
       "        incident_city_Columbus                  -0.12       0.89  125718.07       -246403.01        246402.77                 0.00                  inf\n",
       "        incident_city_Hillsdale                 -0.13       0.88        NaN              NaN              NaN                  NaN                  NaN\n",
       "        incident_city_Northbend                 -0.12       0.88  145676.60       -285521.01        285520.76                 0.00                  inf\n",
       "        incident_city_Northbrook                -0.14       0.87  146460.28       -287057.02        287056.74                 0.00                  inf\n",
       "        incident_city_Riverwood                 -0.11       0.90  232548.06       -455785.92        455785.70                 0.00                  inf\n",
       "        incident_city_Springfield               -0.12       0.88  226809.13       -444537.85        444537.60                 0.00                  inf\n",
       "        incident_hour_of_the_day                 0.00       1.00       0.00            -0.00             0.00                 1.00                 1.00\n",
       "        incident_severity_Major Damage          -0.13       0.88  350151.47       -686284.40        686284.13                 0.00                  inf\n",
       "        incident_severity_Minor Damage          -0.14       0.87  341364.04       -669061.37        669061.08                 0.00                  inf\n",
       "        incident_severity_Total Loss            -0.14       0.87  351579.90       -689084.07        689083.79                 0.00                  inf\n",
       "        incident_severity_Trivial Damage        -0.24       0.79  342871.36       -672015.75        672015.28                 0.00                  inf\n",
       "        incident_state_NC                       -0.11       0.90   23576.61        -46209.41         46209.19                 0.00                  inf\n",
       "        incident_state_NY                       -0.14       0.87   59253.91       -116135.67        116135.40                 0.00                  inf\n",
       "        incident_state_OH                       -0.11       0.89   43925.50        -86092.51         86092.28                 0.00                  inf\n",
       "        incident_state_PA                       -0.09       0.92        NaN              NaN              NaN                  NaN                  NaN\n",
       "        incident_state_SC                       -0.14       0.87   54296.96       -106420.21        106419.94                 0.00                  inf\n",
       "        incident_state_VA                       -0.15       0.86   82658.34       -162007.52        162007.23                 0.00                  inf\n",
       "        incident_state_WV                       -0.14       0.87   52251.03       -102410.29        102410.00                 0.00                  inf\n",
       "        incident_type_Multi-vehicle Collision    0.14       1.15  130565.20       -255902.94        255903.22                 0.00                  inf\n",
       "        incident_type_Parked Car                -1.07       0.34  142519.17       -279333.52        279331.37                 0.00                  inf\n",
       "        incident_type_Single Vehicle Collision   0.14       1.15  133218.41       -261103.13        261103.42                 0.00                  inf\n",
       "        incident_type_Vehicle Theft             -1.03       0.36  134120.23       -262871.86        262869.80                 0.00                  inf\n",
       "        injury_claim                             0.00       1.00       0.00             0.00             0.00                 1.00                 1.00\n",
       "        insured_education_level_Associate       -0.12       0.89  191615.44       -375559.48        375559.24                 0.00                  inf\n",
       "        insured_education_level_College         -0.13       0.88  205078.68       -401946.96        401946.70                 0.00                  inf\n",
       "        insured_education_level_High School     -0.13       0.88  202408.53       -396713.56        396713.31                 0.00                  inf\n",
       "        insured_education_level_JD              -0.12       0.89  202730.11       -397343.83        397343.59                 0.00                  inf\n",
       "        insured_education_level_MD              -0.13       0.88  213529.52       -418510.31        418510.05                 0.00                  inf\n",
       "        insured_education_level_Masters         -0.13       0.88  215951.06       -423256.43        423256.17                 0.00                  inf\n",
       "        insured_education_level_PhD             -0.12       0.89  216775.43       -424872.16        424871.92                 0.00                  inf\n",
       "        insured_hobbies_base-jumping            -0.11       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_hobbies_basketball              -0.13       0.88        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_hobbies_board-games             -0.14       0.87        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_hobbies_bungie-jumping          -0.08       0.92  139685.85       -273779.31        273779.15                 0.00                  inf\n",
       "        insured_hobbies_camping                 -0.07       0.93   83639.66       -163930.78        163930.64                 0.00                  inf\n",
       "        insured_hobbies_chess                   -0.14       0.87   72378.01       -141858.43        141858.15                 0.00                  inf\n",
       "        insured_hobbies_cross-fit               -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_hobbies_dancing                 -0.11       0.90  150351.03       -294682.71        294682.50                 0.00                  inf\n",
       "        insured_hobbies_exercise                -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_hobbies_golf                    -0.09       0.92        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_hobbies_hiking                  -0.13       0.87   26882.55        -52688.97         52688.70                 0.00                  inf\n",
       "        insured_hobbies_kayaking                -0.13       0.88        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_hobbies_movies                  -0.13       0.88   53323.76       -104512.79        104512.53                 0.00                  inf\n",
       "        insured_hobbies_paintball               -0.08       0.92   40903.25        -80168.98         80168.82                 0.00                  inf\n",
       "        insured_hobbies_polo                    -0.14       0.87        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_hobbies_reading                 -0.12       0.89   46179.73        -90510.73         90510.50                 0.00                  inf\n",
       "        insured_hobbies_skydiving               -0.14       0.87  113852.58       -223147.10        223146.82                 0.00                  inf\n",
       "        insured_hobbies_sleeping                -0.11       0.90        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_hobbies_video-games             -0.10       0.90   19008.84        -37256.74         37256.53                 0.00                  inf\n",
       "        insured_hobbies_yachting                -0.10       0.90   18703.62        -36658.53         36658.33                 0.00                  inf\n",
       "        insured_occupation_adm-clerical         -0.13       0.88        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_armed-forces         -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_craft-repair         -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_exec-managerial      -0.10       0.90        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_farming-fishing      -0.07       0.93        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_handlers-cleaners    -0.15       0.86        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_machine-op-inspct    -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_other-service        -0.11       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_priv-house-serv      -0.11       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_prof-specialty       -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_protective-serv      -0.12       0.89        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_sales                -0.11       0.90        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_tech-support         -0.13       0.88        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_occupation_transport-moving     -0.10       0.90        NaN              NaN              NaN                  NaN                  NaN\n",
       "        insured_relationship_husband            -0.13       0.88  133409.12       -261477.19        261476.94                 0.00                  inf\n",
       "        insured_relationship_not-in-family      -0.12       0.89  150639.57       -295248.25        295248.02                 0.00                  inf\n",
       "        insured_relationship_other-relative     -0.13       0.88  151600.92       -297132.46        297132.21                 0.00                  inf\n",
       "        insured_relationship_own-child          -0.13       0.88  142119.77       -278549.75        278549.50                 0.00                  inf\n",
       "        insured_relationship_unmarried          -0.14       0.87  153107.33       -300085.00        300084.72                 0.00                  inf\n",
       "        insured_relationship_wife               -0.14       0.87  133409.12       -261477.21        261476.93                 0.00                  inf\n",
       "        insured_sex_FEMALE                      -0.22       0.80   69021.38       -135279.65        135279.21                 0.00                  inf\n",
       "        insured_sex_MALE                        -0.21       0.81   67492.92       -132283.91        132283.49                 0.00                  inf\n",
       "        months_as_customer                      -0.00       1.00       0.00            -0.00             0.00                 1.00                 1.00\n",
       "        number_of_vehicles_involved             -0.00       1.00       0.02            -0.03             0.03                 0.97                 1.03\n",
       "        police_report_available_NO              -0.26       0.77   52606.47       -103107.04        103106.52                 0.00                  inf\n",
       "        police_report_available_YES             -0.25       0.78   50873.44        -99710.36         99709.86                 0.00                  inf\n",
       "        policy_annual_premium                   -0.00       1.00       0.00            -0.00             0.00                 1.00                 1.00\n",
       "        policy_csl_100/300                      -0.16       0.85        NaN              NaN              NaN                  NaN                  NaN\n",
       "        policy_csl_250/500                      -0.16       0.86        NaN              NaN              NaN                  NaN                  NaN\n",
       "        policy_csl_500/1000                     -0.17       0.85        NaN              NaN              NaN                  NaN                  NaN\n",
       "        policy_deductable                        0.00       1.00       0.00            -0.00             0.00                 1.00                 1.00\n",
       "        policy_state_IL                         -0.18       0.84        NaN              NaN              NaN                  NaN                  NaN\n",
       "        policy_state_IN                         -0.15       0.86        NaN              NaN              NaN                  NaN                  NaN\n",
       "        policy_state_OH                         -0.16       0.85        NaN              NaN              NaN                  NaN                  NaN\n",
       "        property_claim                           0.00       1.00       0.00             0.00             0.00                 1.00                 1.00\n",
       "        property_damage_NO                      -0.25       0.78        NaN              NaN              NaN                  NaN                  NaN\n",
       "        property_damage_YES                     -0.24       0.78        NaN              NaN              NaN                  NaN                  NaN\n",
       "        umbrella_limit                           0.00       1.00       0.00            -0.00             0.00                 1.00                 1.00\n",
       "        vehicle_claim                            0.00       1.00       0.00             0.00             0.00                 1.00                 1.00\n",
       "        witnesses                               -0.00       1.00       0.00            -0.01             0.00                 0.99                 1.00\n",
       "        Intercept                               10.85   51755.35   38130.35        -74723.25         74744.96                 0.00                  inf\n",
       "rho_    Intercept                                2.51      12.32       0.04             2.43             2.59                11.41                13.30\n",
       "\n",
       "                                                 cmp to     z      p   -log2(p)\n",
       "param   covariate                                                              \n",
       "lambda_ age                                        0.00  1.02   0.31       1.70\n",
       "        authorities_contacted_Ambulance            0.00   NaN    NaN        NaN\n",
       "        authorities_contacted_Fire                 0.00   NaN    NaN        NaN\n",
       "        authorities_contacted_None                 0.00   NaN    NaN        NaN\n",
       "        authorities_contacted_Other                0.00   NaN    NaN        NaN\n",
       "        authorities_contacted_Police               0.00   NaN    NaN        NaN\n",
       "        auto_make_Accura                           0.00 -0.00   1.00       0.00\n",
       "        auto_make_Audi                             0.00   NaN    NaN        NaN\n",
       "        auto_make_BMW                              0.00 -0.00   1.00       0.00\n",
       "        auto_make_Chevrolet                        0.00 -0.00   1.00       0.00\n",
       "        auto_make_Dodge                            0.00   NaN    NaN        NaN\n",
       "        auto_make_Ford                             0.00   NaN    NaN        NaN\n",
       "        auto_make_Honda                            0.00 -0.00   1.00       0.00\n",
       "        auto_make_Jeep                             0.00 -0.00   1.00       0.00\n",
       "        auto_make_Mercedes                         0.00 -0.00   1.00       0.00\n",
       "        auto_make_Nissan                           0.00   NaN    NaN        NaN\n",
       "        auto_make_Saab                             0.00   NaN    NaN        NaN\n",
       "        auto_make_Suburu                           0.00   NaN    NaN        NaN\n",
       "        auto_make_Toyota                           0.00   NaN    NaN        NaN\n",
       "        auto_make_Volkswagen                       0.00 -0.00   1.00       0.00\n",
       "        auto_model_3 Series                        0.00 -0.00   1.00       0.00\n",
       "        auto_model_92x                             0.00   NaN    NaN        NaN\n",
       "        auto_model_93                              0.00   NaN    NaN        NaN\n",
       "        auto_model_95                              0.00   NaN    NaN        NaN\n",
       "        auto_model_A3                              0.00   NaN    NaN        NaN\n",
       "        auto_model_A5                              0.00   NaN    NaN        NaN\n",
       "        auto_model_Accord                          0.00 -0.00   1.00       0.00\n",
       "        auto_model_C300                            0.00   NaN    NaN        NaN\n",
       "        auto_model_CRV                             0.00 -0.00   1.00       0.00\n",
       "        auto_model_Camry                           0.00   NaN    NaN        NaN\n",
       "        auto_model_Civic                           0.00 -0.00   1.00       0.00\n",
       "        auto_model_Corolla                         0.00   NaN    NaN        NaN\n",
       "        auto_model_E400                            0.00   NaN    NaN        NaN\n",
       "        auto_model_Escape                          0.00   NaN    NaN        NaN\n",
       "        auto_model_F150                            0.00   NaN    NaN        NaN\n",
       "        auto_model_Forrestor                       0.00 -0.00   1.00       0.00\n",
       "        auto_model_Fusion                          0.00   NaN    NaN        NaN\n",
       "        auto_model_Grand Cherokee                  0.00 -0.00   1.00       0.00\n",
       "        auto_model_Highlander                      0.00   NaN    NaN        NaN\n",
       "        auto_model_Impreza                         0.00 -0.00   1.00       0.00\n",
       "        auto_model_Jetta                           0.00   NaN    NaN        NaN\n",
       "        auto_model_Legacy                          0.00 -0.00   1.00       0.00\n",
       "        auto_model_M5                              0.00 -0.00   1.00       0.00\n",
       "        auto_model_MDX                             0.00 -0.00   1.00       0.00\n",
       "        auto_model_ML350                           0.00   NaN    NaN        NaN\n",
       "        auto_model_Malibu                          0.00 -0.00   1.00       0.00\n",
       "        auto_model_Maxima                          0.00   NaN    NaN        NaN\n",
       "        auto_model_Neon                            0.00 -0.00   1.00       0.00\n",
       "        auto_model_Passat                          0.00   NaN    NaN        NaN\n",
       "        auto_model_Pathfinder                      0.00   NaN    NaN        NaN\n",
       "        auto_model_RAM                             0.00 -0.00   1.00       0.00\n",
       "        auto_model_RSX                             0.00 -0.00   1.00       0.00\n",
       "        auto_model_Silverado                       0.00 -0.00   1.00       0.00\n",
       "        auto_model_TL                              0.00 -0.00   1.00       0.00\n",
       "        auto_model_Tahoe                           0.00 -0.00   1.00       0.00\n",
       "        auto_model_Ultima                          0.00   NaN    NaN        NaN\n",
       "        auto_model_Wrangler                        0.00 -0.00   1.00       0.00\n",
       "        auto_model_X5                              0.00 -0.00   1.00       0.00\n",
       "        auto_model_X6                              0.00 -0.00   1.00       0.00\n",
       "        auto_year                                  0.00  0.94   0.35       1.52\n",
       "        bodily_injuries                            0.00 -1.37   0.17       2.55\n",
       "        capital-gains                              0.00  0.59   0.55       0.85\n",
       "        capital-loss                               0.00  0.87   0.38       1.38\n",
       "        collision_type_Front Collision             0.00   NaN    NaN        NaN\n",
       "        collision_type_Rear Collision              0.00   NaN    NaN        NaN\n",
       "        collision_type_Side Collision              0.00   NaN    NaN        NaN\n",
       "        fraud_reported                             0.00 -0.69   0.49       1.03\n",
       "        incident_city_Arlington                    0.00 -0.00   1.00       0.00\n",
       "        incident_city_Columbus                     0.00 -0.00   1.00       0.00\n",
       "        incident_city_Hillsdale                    0.00   NaN    NaN        NaN\n",
       "        incident_city_Northbend                    0.00 -0.00   1.00       0.00\n",
       "        incident_city_Northbrook                   0.00 -0.00   1.00       0.00\n",
       "        incident_city_Riverwood                    0.00 -0.00   1.00       0.00\n",
       "        incident_city_Springfield                  0.00 -0.00   1.00       0.00\n",
       "        incident_hour_of_the_day                   0.00  0.23   0.82       0.29\n",
       "        incident_severity_Major Damage             0.00 -0.00   1.00       0.00\n",
       "        incident_severity_Minor Damage             0.00 -0.00   1.00       0.00\n",
       "        incident_severity_Total Loss               0.00 -0.00   1.00       0.00\n",
       "        incident_severity_Trivial Damage           0.00 -0.00   1.00       0.00\n",
       "        incident_state_NC                          0.00 -0.00   1.00       0.00\n",
       "        incident_state_NY                          0.00 -0.00   1.00       0.00\n",
       "        incident_state_OH                          0.00 -0.00   1.00       0.00\n",
       "        incident_state_PA                          0.00   NaN    NaN        NaN\n",
       "        incident_state_SC                          0.00 -0.00   1.00       0.00\n",
       "        incident_state_VA                          0.00 -0.00   1.00       0.00\n",
       "        incident_state_WV                          0.00 -0.00   1.00       0.00\n",
       "        incident_type_Multi-vehicle Collision      0.00  0.00   1.00       0.00\n",
       "        incident_type_Parked Car                   0.00 -0.00   1.00       0.00\n",
       "        incident_type_Single Vehicle Collision     0.00  0.00   1.00       0.00\n",
       "        incident_type_Vehicle Theft                0.00 -0.00   1.00       0.00\n",
       "        injury_claim                               0.00 11.56 <0.005     100.21\n",
       "        insured_education_level_Associate          0.00 -0.00   1.00       0.00\n",
       "        insured_education_level_College            0.00 -0.00   1.00       0.00\n",
       "        insured_education_level_High School        0.00 -0.00   1.00       0.00\n",
       "        insured_education_level_JD                 0.00 -0.00   1.00       0.00\n",
       "        insured_education_level_MD                 0.00 -0.00   1.00       0.00\n",
       "        insured_education_level_Masters            0.00 -0.00   1.00       0.00\n",
       "        insured_education_level_PhD                0.00 -0.00   1.00       0.00\n",
       "        insured_hobbies_base-jumping               0.00   NaN    NaN        NaN\n",
       "        insured_hobbies_basketball                 0.00   NaN    NaN        NaN\n",
       "        insured_hobbies_board-games                0.00   NaN    NaN        NaN\n",
       "        insured_hobbies_bungie-jumping             0.00 -0.00   1.00       0.00\n",
       "        insured_hobbies_camping                    0.00 -0.00   1.00       0.00\n",
       "        insured_hobbies_chess                      0.00 -0.00   1.00       0.00\n",
       "        insured_hobbies_cross-fit                  0.00   NaN    NaN        NaN\n",
       "        insured_hobbies_dancing                    0.00 -0.00   1.00       0.00\n",
       "        insured_hobbies_exercise                   0.00   NaN    NaN        NaN\n",
       "        insured_hobbies_golf                       0.00   NaN    NaN        NaN\n",
       "        insured_hobbies_hiking                     0.00 -0.00   1.00       0.00\n",
       "        insured_hobbies_kayaking                   0.00   NaN    NaN        NaN\n",
       "        insured_hobbies_movies                     0.00 -0.00   1.00       0.00\n",
       "        insured_hobbies_paintball                  0.00 -0.00   1.00       0.00\n",
       "        insured_hobbies_polo                       0.00   NaN    NaN        NaN\n",
       "        insured_hobbies_reading                    0.00 -0.00   1.00       0.00\n",
       "        insured_hobbies_skydiving                  0.00 -0.00   1.00       0.00\n",
       "        insured_hobbies_sleeping                   0.00   NaN    NaN        NaN\n",
       "        insured_hobbies_video-games                0.00 -0.00   1.00       0.00\n",
       "        insured_hobbies_yachting                   0.00 -0.00   1.00       0.00\n",
       "        insured_occupation_adm-clerical            0.00   NaN    NaN        NaN\n",
       "        insured_occupation_armed-forces            0.00   NaN    NaN        NaN\n",
       "        insured_occupation_craft-repair            0.00   NaN    NaN        NaN\n",
       "        insured_occupation_exec-managerial         0.00   NaN    NaN        NaN\n",
       "        insured_occupation_farming-fishing         0.00   NaN    NaN        NaN\n",
       "        insured_occupation_handlers-cleaners       0.00   NaN    NaN        NaN\n",
       "        insured_occupation_machine-op-inspct       0.00   NaN    NaN        NaN\n",
       "        insured_occupation_other-service           0.00   NaN    NaN        NaN\n",
       "        insured_occupation_priv-house-serv         0.00   NaN    NaN        NaN\n",
       "        insured_occupation_prof-specialty          0.00   NaN    NaN        NaN\n",
       "        insured_occupation_protective-serv         0.00   NaN    NaN        NaN\n",
       "        insured_occupation_sales                   0.00   NaN    NaN        NaN\n",
       "        insured_occupation_tech-support            0.00   NaN    NaN        NaN\n",
       "        insured_occupation_transport-moving        0.00   NaN    NaN        NaN\n",
       "        insured_relationship_husband               0.00 -0.00   1.00       0.00\n",
       "        insured_relationship_not-in-family         0.00 -0.00   1.00       0.00\n",
       "        insured_relationship_other-relative        0.00 -0.00   1.00       0.00\n",
       "        insured_relationship_own-child             0.00 -0.00   1.00       0.00\n",
       "        insured_relationship_unmarried             0.00 -0.00   1.00       0.00\n",
       "        insured_relationship_wife                  0.00 -0.00   1.00       0.00\n",
       "        insured_sex_FEMALE                         0.00 -0.00   1.00       0.00\n",
       "        insured_sex_MALE                           0.00 -0.00   1.00       0.00\n",
       "        months_as_customer                         0.00 -1.06   0.29       1.79\n",
       "        number_of_vehicles_involved                0.00 -0.05   0.96       0.05\n",
       "        police_report_available_NO                 0.00 -0.00   1.00       0.00\n",
       "        police_report_available_YES                0.00 -0.00   1.00       0.00\n",
       "        policy_annual_premium                      0.00 -0.53   0.60       0.75\n",
       "        policy_csl_100/300                         0.00   NaN    NaN        NaN\n",
       "        policy_csl_250/500                         0.00   NaN    NaN        NaN\n",
       "        policy_csl_500/1000                        0.00   NaN    NaN        NaN\n",
       "        policy_deductable                          0.00  0.84   0.40       1.33\n",
       "        policy_state_IL                            0.00   NaN    NaN        NaN\n",
       "        policy_state_IN                            0.00   NaN    NaN        NaN\n",
       "        policy_state_OH                            0.00   NaN    NaN        NaN\n",
       "        property_claim                             0.00 12.25 <0.005     112.22\n",
       "        property_damage_NO                         0.00   NaN    NaN        NaN\n",
       "        property_damage_YES                        0.00   NaN    NaN        NaN\n",
       "        umbrella_limit                             0.00  0.48   0.63       0.67\n",
       "        vehicle_claim                              0.00 28.29 <0.005     582.42\n",
       "        witnesses                                  0.00 -0.85   0.39       1.34\n",
       "        Intercept                                  0.00  0.00   1.00       0.00\n",
       "rho_    Intercept                                  0.00 64.00 <0.005        inf\n",
       "---\n",
       "Concordance = 0.96\n",
       "AIC = 10063.78\n",
       "log-likelihood ratio test = 1951.30 on 158 df\n",
       "-log2(p) of ll-ratio test = 1015.09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Fit a Weibull Harzard Model to predict the total_claim_amount, using the data in the df dataframe, with the rest of the columns as independent variables\n",
    "\n",
    "from lifelines import WeibullAFTFitter\n",
    "\n",
    "# Create a WeibullAFTFitter object\n",
    "model = WeibullAFTFitter()\n",
    "\n",
    "# Fit the model with 'total_claim_amount' as the dependent variable and the rest of the columns as independent variables\n",
    "model.fit(train, duration_col='total_claim_amount')\n",
    "\n",
    "# Get the estimated parameters of the model\n",
    "print(model.print_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the total_claim_amount\n",
    "predicted_survival_times = model.predict_expectation(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIT values: [0.43912176 0.57085828 0.91616766 0.92914172 0.27145709 0.1237525\n",
      " 0.69860279 0.96606786 0.10179641 0.05289421 0.17964072 0.91317365\n",
      " 0.02994012 0.38323353 0.18862275 0.43413174 0.04191617 0.25349301\n",
      " 0.94011976 0.85628743 0.4750499  0.21956088 0.9261477  0.4251497\n",
      " 0.8762475  0.97005988 0.51896208 0.83033932 0.26946108 0.21357285\n",
      " 0.77045908 0.28942116 0.6506986  0.24151697 0.15668663 0.61676647\n",
      " 0.98203593 0.03393214 0.81636727 0.5489022  0.81836327 0.62974052\n",
      " 0.45708583 0.79640719 0.06187625 0.63872255 0.5249501  0.83333333\n",
      " 0.55588822 0.86027944 0.99401198 0.98802395 0.60379242 0.8253493\n",
      " 0.67065868 0.59281437 0.45309381 0.55588822 0.39121756 0.49700599\n",
      " 0.28143713 0.51297405 0.68662675 0.69261477 0.51896208 0.29241517\n",
      " 0.02095808 0.14670659 0.39620758 0.05788423 0.26047904 0.08183633\n",
      " 0.57884232 0.0249501  0.499002   0.0489022  0.89820359 0.41716567\n",
      " 0.3992016  0.44111776 0.2255489  0.8003992  0.05788423 0.56487026\n",
      " 0.16167665 0.94810379 0.249501   0.14670659 0.40518962 0.89121756\n",
      " 0.5748503  0.40718563 0.95209581 0.27944112 0.1756487  0.88223553\n",
      " 0.53493014 0.4011976  0.15269461 0.03992016 0.62974052 0.65269461\n",
      " 0.64870259 0.48902196 0.63273453 0.89421158 0.94211577 0.48602794\n",
      " 0.01596806 0.68862275 0.21756487 0.36127745 0.9500998  0.88822355\n",
      " 0.36726547 0.0748503  0.09580838 0.72055888 0.56886228 0.00798403\n",
      " 0.26546906 0.59680639 0.03792415 0.65868263 0.66866267 0.43413174\n",
      " 0.93612774 0.2994012  0.55189621 0.42315369 0.35928144 0.63672655\n",
      " 0.26347305 0.88622754 0.9241517  0.29640719 0.70858283 0.24351297\n",
      " 0.8742515  0.75449102 0.09381238 0.40319361 0.30439122 0.13073852\n",
      " 0.20958084 0.16766467 0.61876248 0.35528942 0.60878244 0.51896208\n",
      " 0.60678643 0.81237525 0.06387226 0.50598802 0.76047904 0.61277445\n",
      " 0.68463074 0.79341317 0.6007984  0.38722555 0.34031936 0.53193613\n",
      " 0.48602794 0.7245509  0.37125749 0.13073852 0.16966068 0.76646707\n",
      " 0.84630739 0.58283433 0.71257485 0.32035928 0.96007984 0.83333333\n",
      " 0.2754491  0.11077844 0.54491018 0.81437126 0.28343313 0.06986028\n",
      " 0.32734531 0.16367265 0.83932136 0.9001996  0.99600798 0.39620758\n",
      " 0.08383234 0.03592814 0.87125749 0.56686627 0.00199601 0.57684631\n",
      " 0.23552894 0.47704591 0.04391218 0.4491018  0.97804391 0.14071856\n",
      " 0.46007984 0.66666667 0.3502994  0.82035928 0.67964072 0.71257485\n",
      " 0.68263473 0.25149701 0.38123752 0.85429142 0.34730539 0.47904192\n",
      " 0.55988024 0.76846307 0.92914172 0.93812375 0.21556886 0.35329341\n",
      " 0.38922156 0.50299401 0.7744511  0.53193613 0.73552894 0.67964072\n",
      " 0.98003992 0.64670659 0.00798403 0.78043912 0.10379242 0.78243513\n",
      " 0.95808383 0.58083832 0.59481038 0.48203593 0.46706587 0.99800399\n",
      " 0.43013972 0.41317365 0.33133733 0.44311377 0.18163673 0.87924152\n",
      " 0.18363273 0.28542914 0.9760479  0.89121756 0.90219561 0.3762475\n",
      " 0.66367265 0.46906188 0.41916168 0.16566866 0.54091816 0.34530938\n",
      " 0.81037924 0.1497006  0.37924152 0.73552894 0.30439122 0.26746507\n",
      " 0.0748503  0.31337325 0.49401198 0.66067864 0.06986028 0.73552894\n",
      " 0.30738523 0.3502994  0.75648703 0.51896208 0.31736527 0.65469062\n",
      " 0.75249501 0.23353293 0.90818363 0.50898204 0.50598802 0.11976048\n",
      " 0.00798403 0.5988024  0.53892216 0.11477046 0.59081836 0.62674651\n",
      " 0.71856287 0.28742515 0.54291417 0.69461078 0.07884232 0.73552894\n",
      " 0.12774451 0.4491018  0.46307385 0.26047904 0.82235529 0.58682635\n",
      " 0.25548902 0.52894212 0.54690619 0.63473054 0.98602794 0.36526946\n",
      " 0.91017964 0.90618762 0.36327345 0.98403194 0.51097804 0.62275449\n",
      " 0.23153693 0.18862275 0.74051896 0.1257485  0.33532934 0.09181637\n",
      " 0.20159681 0.94411178 0.9740519  0.36926148 0.83632735 0.64471058\n",
      " 0.70658683 0.96207585 0.29241517 0.08582834 0.92215569 0.86427146\n",
      " 0.34031936 0.25748503 0.3762475  0.08782435 0.93413174 0.96806387\n",
      " 0.75848303 0.84630739 0.0249501  0.69061876 0.46506986 0.61077844\n",
      " 0.74650699 0.95608782 0.74451098 0.15269461 0.64271457 0.45508982\n",
      " 0.07884232 0.66367265 0.69660679 0.500998   0.30938124 0.52694611\n",
      " 0.41117764 0.19760479 0.90419162 0.750499   0.99201597 0.83932136\n",
      " 0.01397206 0.29640719 0.21157685 0.40918164 0.35728543 0.34331337\n",
      " 0.91816367 0.6247505  0.27345309 0.71257485 0.76447106 0.13473054\n",
      " 0.24750499 0.04590818 0.67664671 0.43013972 0.60379242 0.84630739\n",
      " 0.33732535 0.8502994  0.80638723 0.49401198 0.86826347 0.89620758\n",
      " 0.0998004  0.11776447 0.03193613 0.42115768 0.23952096 0.79041916\n",
      " 0.47105788 0.08982036 0.02095808 0.47305389 0.01197605 0.41516966\n",
      " 0.09780439 0.71656687 0.85828343 0.11477046 0.73053892 0.87125749\n",
      " 0.02794411 0.8253493  0.72255489 0.48203593 0.19361277 0.61477046\n",
      " 0.55189621 0.12175649 0.33333333 0.22954092 0.72654691 0.88423154\n",
      " 0.77245509 0.23752495 0.17365269 0.58483034 0.51896208 0.13772455\n",
      " 0.55988024 0.46007984 0.22155689 0.31137725 0.01796407 0.91317365\n",
      " 0.24550898 0.43712575 0.78443114 0.74850299 0.85229541 0.17764471\n",
      " 0.78642715 0.30139721 0.77744511 0.94610778 0.80638723 0.18562874\n",
      " 0.32335329 0.19560878 0.80638723 0.06586826 0.53692615 0.05289421\n",
      " 0.70359281 0.32934132 0.22754491 0.00399202 0.57285429 0.3253493\n",
      " 0.86227545 0.79840319 0.92015968 0.99001996 0.80239521 0.82834331\n",
      " 0.10578842 0.06986028 0.15668663 0.86626747 0.37325349 0.39321357\n",
      " 0.14071856 0.87924152 0.10778443 0.19161677 0.27744511 0.0489022\n",
      " 0.05788423 0.1996008  0.72854291 0.76247505 0.44510978 0.78842315\n",
      " 0.32035928 0.96407186 0.93213573 0.7005988  0.74251497 0.58882236\n",
      " 0.31536926 0.62075848 0.56287425 0.79341317 0.95409182 0.77744511\n",
      " 0.49101796 0.20558882 0.17165669 0.14371257 0.70359281 0.15968064\n",
      " 0.65668663 0.67365269 0.13473054 0.67365269 0.4491018  0.38522954\n",
      " 0.42714571 0.64071856 0.20359281 0.97205589 0.20758483 0.11077844\n",
      " 0.84231537 0.22355289]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "def pit_transform(predictions, actual_values):\n",
    "    ranks = rankdata(actual_values) / (len(actual_values) + 1)\n",
    "    transformed_values = np.zeros_like(predictions)\n",
    "    transformed_values[np.argsort(predictions)] = ranks\n",
    "    return transformed_values\n",
    "\n",
    "actual_claim_amounts = test['total_claim_amount'].values\n",
    "\n",
    "pit_values = pit_transform(predicted_survival_times, actual_claim_amounts)\n",
    "\n",
    "print(\"PIT values:\", pit_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the PIT values as an Histogram\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "plt.hist(pit_values, bins=30, range=(0,1), color='blue', edgecolor='black', linewidth=1.2, alpha=0.5, label='PIT values', density=True)\n",
    "plt.title('Histogram of PIT values')\n",
    "plt.xlabel('PIT values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Data - Poisson Regression for Amount of Vehicles Involved in the Claim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the following section is to generate a prediction model for the amount of vehicules involved in the claims. The model will be based on a Poisson Regression, which is a generalized linear model (GLM) for predicting count data.\n",
    "\n",
    "By using a Poisson model to predict the number of vehicles involved in an accident claim, the insurance company can estimate the expected number of vehicles involved in a claim and assess the associated risk and potential financial impact. This information can be used to adjust premiums, determine appropriate reserves for future claims, and identify areas for risk mitigation.\n",
    "\n",
    "Additionally, the insurance company can use the Poisson model to analyze the impact of different variables on the number of vehicles involved in a claim, such as the policyholder's age, sex, education level, occupation, or location. This information can be used to identify high-risk policyholders or regions and develop targeted risk management strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.00000\n",
       "mean        1.83900\n",
       "std         1.01888\n",
       "min         1.00000\n",
       "25%         1.00000\n",
       "50%         1.00000\n",
       "75%         3.00000\n",
       "max         4.00000\n",
       "Name: number_of_vehicles_involved, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the number of vehicle involded\n",
    "df['number_of_vehicles_involved'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PoissonRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Poisson Model to Predict the Amount of vehicules involved\n",
    "\n",
    "# Load the data and split into train and test sets\n",
    "X = df.drop('number_of_vehicles_involved', axis=1)\n",
    "y = df['number_of_vehicles_involved']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.40, random_state=42)\n",
    "\n",
    "# Scale the predictor variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit a Poisson regression model on the training data\n",
    "poisson_model = PoissonRegressor()\n",
    "poisson_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = poisson_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.8340154044998109\n",
      "MAE: 0.31667806976968604\n",
      "MSE: 0.17591773613715347\n",
      "Adjusted R2: 0.7730402659893957\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance\n",
    "print('R2 Score:', r2_score(y_test, y_pred))\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Create a funciton to calculate the adjusted R2\n",
    "def adj_r2(X,y):\n",
    "    r2 = poisson_model.score(X,y)\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2\n",
    "\n",
    "# Calculate the adjusted R2\n",
    "print('Adjusted R2:', adj_r2(X_test_scaled, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the Poisson model suggest that the model is a good fit for the data, with an R2 score of 0.834 indicating that the model explains approximately 83% of the variance in the count of cars involved in an accident claim. This suggests that the model has a good ability to capture the underlying relationships between the predictor variables and the count of cars involved in the accident claim.\n",
    "\n",
    "Additionally, the mean absolute error (MAE) of 0.317 suggests that the model's predictions are off by an average of 0.317, which is relatively small in the context of the data. This indicates that the model's predictions are quite accurate in terms of the count of cars involved in the accident claim.\n",
    "\n",
    "Moreover, the mean squared error (MSE) of 0.176 suggests that the model's predictions have a relatively small spread of errors compared to the mean absolute error, which is another positive aspect of the model's performance.\n",
    "\n",
    "Finally, the adjusted R2 of 0.773 suggests that the model's performance is not impacted significantly by the number of predictor variables used. Overall, the results suggest that the Poisson model is a good starting point for predicting the count of cars involved in an accident claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number of vehicles involved: 1.145132203012557\n",
      "Actual number of vehicles involved: 1\n"
     ]
    }
   ],
   "source": [
    "# Predict the number of vehicles involved in an accident for a random observation\n",
    "print('Predicted number of vehicles involved:', poisson_model.predict(X_test_scaled[0].reshape(1,-1))[0])\n",
    "print('Actual number of vehicles involved:', y_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vehicles involved in the accident distribution:\n",
      "1    0.581\n",
      "3    0.358\n",
      "4    0.031\n",
      "2    0.030\n",
      "Name: number_of_vehicles_involved, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Number of vehicles involved in the accident distribution\n",
    "print('Number of vehicles involved in the accident distribution:')\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Poisson PMF\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Create a function to calculate the probability of accidents involving 1, 2, 3, and 4 vehicles given the model, and returning a single percentage per number of vehicles using PMF, considering the any desired observation\n",
    "def proba_vehicles(model, observation):\n",
    "    # Create a list of the number of vehicles involved in the accident\n",
    "    vehicles = [1,2,3,4]\n",
    "    # Create an empty list to store the probabilities\n",
    "    probabilities = []\n",
    "    # Loop through the vehicles list\n",
    "    for vehicle in vehicles:\n",
    "        # Calculate the probability of the number of vehicles involved in the accident\n",
    "        probability = poisson.pmf(vehicle, model.predict(observation)[0])\n",
    "        # Append the probability to the list\n",
    "        probabilities.append(probability)\n",
    "    # Return the probabilities\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.3643602833192999, 0.20862034696385467, 0.07963262583732097, 0.022797471064191496]\n"
     ]
    }
   ],
   "source": [
    "# Print the probabilities for the first observation\n",
    "print('Probabilities:', proba_vehicles(poisson_model, X_test_scaled[0].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number of vehicles involved: 1\n"
     ]
    }
   ],
   "source": [
    "# Print the actual number of vehicles involved in the first observation\n",
    "print('Actual number of vehicles involved:', y_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.18818959503421695, 0.2485744644641002, 0.21889011937625832, 0.14456297169496368]\n"
     ]
    }
   ],
   "source": [
    "# Print the probabilities for the second observation\n",
    "print('Probabilities:', proba_vehicles(poisson_model, X_test_scaled[1].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number of vehicles involved: 3\n"
     ]
    }
   ],
   "source": [
    "# Print the actual number of vehicles involved in the second observation\n",
    "print('Actual number of vehicles involved:', y_test.iloc[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous generated tool can help calculate the probabilities for each of the possible results on any of the data rows, given the values of the predictor variables. It can be useful for assessing the likelihood of accidents with specific vehicle counts, which can inform decision-making, risk assessment, and policy development for the insurance company.\n",
    "\n",
    "These probabilities may provide insights for insurance companies and policy makers when assessing risk and designing policies related to auto accidents. It may be helpful to investigate the causes of accidents involving multiple vehicles and to determine ways to mitigate these risks, such as improving road infrastructure and safety measures.\n",
    "\n",
    "From the observations we can observed a close relationship between the predicted value, and their probability."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Fraud Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section is focused on generating a prediction model for the fraud probability. The model will be based on a Neural Network Model, which is a machine learning model that can be used to predict the probability of an event occurring.\n",
    "\n",
    "As a business problem, a machine learning model can help insurance companies to detect and prevent fraud more accurately and efficiently, reducing financial losses and maintaining lower premiums for policyholders. By analyzing historical data and identifying patterns indicative of fraud, the model can prioritize investigations and allocate resources more effectively, improving overall risk management for the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    753\n",
      "1    247\n",
      "Name: fraud_reported_Y, dtype: int64\n",
      "1    753\n",
      "0    247\n",
      "Name: fraud_reported_N, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the df columns fraund_reported_Yes and fraud_reported_No\n",
    "print(df['fraud_reported_Y'].value_counts())\n",
    "print(df['fraud_reported_N'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring back the fraud_reported column into a single binary column, based on the fraud_reported column\n",
    "df['fraud_reported'] = df['fraud_reported_Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the fraud_reported_Y and fraud_reported_N columns\n",
    "df.drop(['fraud_reported_Y', 'fraud_reported_N'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dependent and independent variables\n",
    "X = df.drop('fraud_reported', axis=1)\n",
    "y = df['fraud_reported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                2544      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Fit a neural network model to predict fraud_reported using Keras\n",
    "\n",
    "# Import the required libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Create a function to create a neural network model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    adam=Adam(lr=0.0001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a model\n",
    "model = create_model()\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 860us/step - loss: 101584.9141 - accuracy: 0.2560\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 882us/step - loss: 95369.7031 - accuracy: 0.2560\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 89383.7891 - accuracy: 0.2560\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 817us/step - loss: 83535.6016 - accuracy: 0.2560\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 77114.9531 - accuracy: 0.2560\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 63070.7383 - accuracy: 0.2560\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 964us/step - loss: 46473.6055 - accuracy: 0.2560\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 859us/step - loss: 31689.2637 - accuracy: 0.2560\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 17289.6465 - accuracy: 0.2560\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 878us/step - loss: 5694.3579 - accuracy: 0.2780\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 3610.0977 - accuracy: 0.3040\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 3048.2927 - accuracy: 0.3040\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 838us/step - loss: 2691.1833 - accuracy: 0.3280\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 819us/step - loss: 2419.9160 - accuracy: 0.3080\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 919us/step - loss: 2160.2942 - accuracy: 0.3980\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 837us/step - loss: 2042.3975 - accuracy: 0.4460\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 1885.0087 - accuracy: 0.4660\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 1888.7102 - accuracy: 0.4760\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 799us/step - loss: 1759.9495 - accuracy: 0.4920\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 840us/step - loss: 1717.6508 - accuracy: 0.4960\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 1603.3610 - accuracy: 0.5060\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 1583.1591 - accuracy: 0.5240\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 795us/step - loss: 1490.2595 - accuracy: 0.5560\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 1499.8184 - accuracy: 0.5600\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 1414.4258 - accuracy: 0.5720\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 774us/step - loss: 1458.8245 - accuracy: 0.5740\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 795us/step - loss: 1517.8147 - accuracy: 0.5600\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 1327.7087 - accuracy: 0.5840\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 837us/step - loss: 1298.7512 - accuracy: 0.5640\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1278.6107 - accuracy: 0.5720\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 922us/step - loss: 1266.7841 - accuracy: 0.5740\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 1226.1810 - accuracy: 0.5660\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 919us/step - loss: 1240.0741 - accuracy: 0.5740\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 879us/step - loss: 1169.5400 - accuracy: 0.5760\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 876us/step - loss: 1184.4438 - accuracy: 0.5780\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 857us/step - loss: 1183.5051 - accuracy: 0.5880\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 856us/step - loss: 1323.4850 - accuracy: 0.5840\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 1141.4971 - accuracy: 0.5980\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 856us/step - loss: 1093.5382 - accuracy: 0.5940\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 899us/step - loss: 1101.2324 - accuracy: 0.5880\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 1054.5488 - accuracy: 0.5920\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 1028.1832 - accuracy: 0.6020\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 825us/step - loss: 1005.1403 - accuracy: 0.6120\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 992.8405 - accuracy: 0.5920\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 989.3526 - accuracy: 0.5980\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 950.4933 - accuracy: 0.5860\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 887.9897 - accuracy: 0.5960\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 895.1454 - accuracy: 0.5920\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 855.0820 - accuracy: 0.6080\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 833.1312 - accuracy: 0.6060\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 799.9786 - accuracy: 0.6080\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 790.2266 - accuracy: 0.6080\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 856us/step - loss: 755.4890 - accuracy: 0.6100\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 798us/step - loss: 781.7181 - accuracy: 0.6160\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 963us/step - loss: 707.7550 - accuracy: 0.6340\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 746.9047 - accuracy: 0.6000\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 856us/step - loss: 695.7656 - accuracy: 0.6240\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 708.9568 - accuracy: 0.6100\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 701.8804 - accuracy: 0.6320\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 600.1157 - accuracy: 0.6420\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 623.8926 - accuracy: 0.6220\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 689.6177 - accuracy: 0.6340\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 879us/step - loss: 598.8497 - accuracy: 0.6320\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 597.1083 - accuracy: 0.6320\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 608.0502 - accuracy: 0.6380\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 796us/step - loss: 556.5026 - accuracy: 0.6520\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 511.4029 - accuracy: 0.6540\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 501.4122 - accuracy: 0.6560\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 500.3656 - accuracy: 0.6420\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 898us/step - loss: 484.0016 - accuracy: 0.6580\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 527.3367 - accuracy: 0.6560\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 443.3742 - accuracy: 0.6400\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 439.6297 - accuracy: 0.6580\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 961us/step - loss: 547.5061 - accuracy: 0.6640\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 859us/step - loss: 443.3964 - accuracy: 0.6580\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 403.9236 - accuracy: 0.6680\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 406.8993 - accuracy: 0.6660\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 858us/step - loss: 399.8293 - accuracy: 0.6620\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 437.7200 - accuracy: 0.6760\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 511.3961 - accuracy: 0.6620\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 427.2503 - accuracy: 0.6580\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 346.1454 - accuracy: 0.6700\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 837us/step - loss: 349.0384 - accuracy: 0.6720\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 795us/step - loss: 530.3699 - accuracy: 0.6700\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 376.4446 - accuracy: 0.6740\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 856us/step - loss: 295.0997 - accuracy: 0.6720\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 877us/step - loss: 346.5838 - accuracy: 0.6700\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 286.1359 - accuracy: 0.6680\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 879us/step - loss: 354.5673 - accuracy: 0.6740\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 449.0375 - accuracy: 0.6840\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 800us/step - loss: 270.3151 - accuracy: 0.6780\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 775us/step - loss: 344.5203 - accuracy: 0.6700\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 838us/step - loss: 289.3315 - accuracy: 0.6840\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 249.5966 - accuracy: 0.6840\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 233.7396 - accuracy: 0.6780\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 919us/step - loss: 225.4936 - accuracy: 0.6840\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 826us/step - loss: 227.8181 - accuracy: 0.6800\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 795us/step - loss: 204.3176 - accuracy: 0.6820\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 797us/step - loss: 203.1313 - accuracy: 0.6840\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 210.8730 - accuracy: 0.6900\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 172.9278 - accuracy: 0.6960\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 859us/step - loss: 182.2493 - accuracy: 0.6940\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 165.3486 - accuracy: 0.7000\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 151.8664 - accuracy: 0.6860\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 860us/step - loss: 235.5039 - accuracy: 0.6780\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 857us/step - loss: 177.4173 - accuracy: 0.7020\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 140.9645 - accuracy: 0.6860\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 256.7526 - accuracy: 0.7020\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 817us/step - loss: 143.3233 - accuracy: 0.7080\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 792us/step - loss: 177.1365 - accuracy: 0.7060\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 813us/step - loss: 115.4682 - accuracy: 0.7080\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 774us/step - loss: 271.8138 - accuracy: 0.7140\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 267.8830 - accuracy: 0.7060\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 774us/step - loss: 245.7496 - accuracy: 0.7160\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 859us/step - loss: 131.3003 - accuracy: 0.7200\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 103.5227 - accuracy: 0.7140\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 799us/step - loss: 172.1206 - accuracy: 0.6900\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 837us/step - loss: 249.7902 - accuracy: 0.7200\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 773us/step - loss: 96.7384 - accuracy: 0.7160\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 108.1412 - accuracy: 0.7140\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 91.7867 - accuracy: 0.7240\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 157.5795 - accuracy: 0.6960\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 773us/step - loss: 126.0354 - accuracy: 0.7120\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 89.7739 - accuracy: 0.7120\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 74.8898 - accuracy: 0.7200\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 103.7821 - accuracy: 0.7120\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 941us/step - loss: 78.1873 - accuracy: 0.7140\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 156.9282 - accuracy: 0.7040\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 822us/step - loss: 119.2882 - accuracy: 0.7020\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 149.4724 - accuracy: 0.7180\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 773us/step - loss: 103.9080 - accuracy: 0.7040\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 84.1962 - accuracy: 0.7220\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 65.6785 - accuracy: 0.7200\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 796us/step - loss: 100.6979 - accuracy: 0.7120\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 79.7411 - accuracy: 0.7220\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 83.1519 - accuracy: 0.7180\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 147.4187 - accuracy: 0.7040\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 106.5772 - accuracy: 0.7020\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 798us/step - loss: 136.9856 - accuracy: 0.7200\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 101.0618 - accuracy: 0.7180\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 100.8735 - accuracy: 0.7260\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 59.8241 - accuracy: 0.7200\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 858us/step - loss: 260.5841 - accuracy: 0.7260\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 236.6805 - accuracy: 0.7100\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 162.0647 - accuracy: 0.7100\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 775us/step - loss: 104.3060 - accuracy: 0.7340\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 117.0851 - accuracy: 0.7140\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 65.6028 - accuracy: 0.7300\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 108.8302 - accuracy: 0.7180\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 64.7561 - accuracy: 0.7180\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 67.7055 - accuracy: 0.7280\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 73.0453 - accuracy: 0.7240\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 92.0228 - accuracy: 0.7240\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 940us/step - loss: 214.5239 - accuracy: 0.6900\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 162.3429 - accuracy: 0.7100\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 856us/step - loss: 75.8440 - accuracy: 0.7120\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 882us/step - loss: 94.6185 - accuracy: 0.7120\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 837us/step - loss: 121.7888 - accuracy: 0.7120\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 200.3643 - accuracy: 0.7220\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 107.9793 - accuracy: 0.7120\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 93.3710 - accuracy: 0.7200\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 877us/step - loss: 77.9244 - accuracy: 0.7220\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 797us/step - loss: 85.7734 - accuracy: 0.7220\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 856us/step - loss: 86.9222 - accuracy: 0.7160\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 845us/step - loss: 96.8310 - accuracy: 0.7260\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 898us/step - loss: 126.4498 - accuracy: 0.7160\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 125.2223 - accuracy: 0.7320\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 857us/step - loss: 79.8270 - accuracy: 0.7280\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 56.1008 - accuracy: 0.7220\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 839us/step - loss: 132.0532 - accuracy: 0.7060\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 146.5166 - accuracy: 0.7020\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 223.8509 - accuracy: 0.7200\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 856us/step - loss: 61.4630 - accuracy: 0.7200\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 74.6268 - accuracy: 0.7240\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 103.4696 - accuracy: 0.7180\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 180.2107 - accuracy: 0.7260\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 819us/step - loss: 78.1538 - accuracy: 0.7140\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 77.7383 - accuracy: 0.7300\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 71.9364 - accuracy: 0.7020\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 837us/step - loss: 112.7830 - accuracy: 0.7120\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 839us/step - loss: 194.8993 - accuracy: 0.7200\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 878us/step - loss: 122.5398 - accuracy: 0.7080\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 795us/step - loss: 144.1740 - accuracy: 0.7060\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 857us/step - loss: 73.7513 - accuracy: 0.7240\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 111.2015 - accuracy: 0.7120\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 101.9646 - accuracy: 0.7100\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 859us/step - loss: 96.3812 - accuracy: 0.7080\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 60.3906 - accuracy: 0.7200\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 150.6332 - accuracy: 0.7140\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 105.0478 - accuracy: 0.7040\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 125.3317 - accuracy: 0.7140\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 856us/step - loss: 104.1217 - accuracy: 0.7080\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 752us/step - loss: 85.2972 - accuracy: 0.7240\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 81.2525 - accuracy: 0.7220\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 63.5610 - accuracy: 0.7140\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 72.4555 - accuracy: 0.7220\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 940us/step - loss: 86.4855 - accuracy: 0.6940\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 59.8503 - accuracy: 0.7300\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 837us/step - loss: 110.1330 - accuracy: 0.7100\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 924us/step - loss: 166.7035 - accuracy: 0.7040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c51cee83d0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 639us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.658\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score\n",
    "print(accuracy_score(y_test,y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[301  80]\n",
      " [ 91  28]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test,y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the confusion matrix\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred.round()),annot=True,fmt='d');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy does not to seem that great, with only a score of 66% accuracy. Let's see if we can improve it by hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 1664.0751 - accuracy: 0.7140\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.7890 - accuracy: 0.7380\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.7440\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.6329 - accuracy: 0.7440\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6201 - accuracy: 0.7440\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.7440\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.7440\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.7440\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5886 - accuracy: 0.7440\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5841 - accuracy: 0.7440\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.7440\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5781 - accuracy: 0.7440\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.7440\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 999us/step - loss: 0.5740 - accuracy: 0.7440\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7440\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5716 - accuracy: 0.7440\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 940us/step - loss: 0.5709 - accuracy: 0.7440\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7440\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7440\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 939us/step - loss: 0.5697 - accuracy: 0.7440\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7440\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5693 - accuracy: 0.7440\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5692 - accuracy: 0.7440\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5691 - accuracy: 0.7440\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 939us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 876us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 939us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 941us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 999us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 939us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 941us/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 941us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5692 - accuracy: 0.7440\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 876us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 939us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 929us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 936us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 879us/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 874us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7440\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 941us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 936us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 940us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 877us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 939us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 936us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Best: 0.746074 using {'activation': 'relu', 'batch_size': 60, 'epochs': 200, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define a function to create a Keras model\n",
    "def create_model(learning_rate=0.01, activation='relu'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=X_train.shape[1], activation=activation))\n",
    "    model.add(Dense(8, activation=activation))\n",
    "    model.add(Dense(4, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define hyperparameters\n",
    "param_grid = {'batch_size': [20, 40, 60, 80, 100],\n",
    "                'epochs': [100, 200, 300, 400, 500],\n",
    "                'learning_rate': [0.01, 0.001, 0.0001],\n",
    "                'activation': ['relu', 'tanh']}\n",
    "\n",
    "# Create a KerasClassifier object\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "\n",
    "# Fit the GridSearchCV object with the data\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After model optimization we are able to improve accuracy from 63% to 75%, which is a good improvement. However, the model is still not very accurate, a good reason might be the imbalance of the data, which is something to keep in mind, but it's also the nature of fraud.\n",
    "\n",
    "Still remains as a valid model for fraud prediction, and that the insurance company can use to first screen the claims and prioritize the ones that are more likely to be fraud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
